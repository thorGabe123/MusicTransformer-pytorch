{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import processor\n",
    "from data import Data, preprocess_midi_files_under\n",
    "import torch\n",
    "from model import load_config, load_model\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\chan01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\chan02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\cho01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\cho02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\cho03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\cho04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\cho05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\dossin01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\dossin02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\dossin03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\dossin04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\dossin05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\dossin06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\dossin07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\dvorkine01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\dvorkine02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\dvorkine03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\dvorkine04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\franceschetti01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\franceschetti02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\franceschetti03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\giltburg01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\giltburg02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\giltburg03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\giltburg04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\giltburg05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\guttman01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\guttman02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\guttman03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\guttman04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\guttman05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\hannumizzard01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\hannumizzard02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\hannumizzard03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\hannumizzard04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\hireche01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\hireche02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\hireche03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\hireche04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\huang01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\huang02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\huang03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\kolessova01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\kolessova02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\kolessova03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\kolessova04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\kolessova05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\kolessova06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\kolessova07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\lim01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\lim02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\lim03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\lim04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\lim05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\lin01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\lin02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\lin03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\lin04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\lin05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\lin06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\lin07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\malan01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\malan02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\malan03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\malan04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\malan05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\malan06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\malan07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\mamriev01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\mamriev02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\mamriev03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\mamriev04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\mamriev05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\mikhailoff01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\mikhailoff02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\mikhailoff03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\mikhailoff04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\mikhailoff05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\morozov01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\morozov02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\morozov03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\morozov04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\morozov05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\park01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\park02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\park03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\park04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\park05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\savitski01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\savitski02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\savitski03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\savitski04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\savitski05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\savitski06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\soloman01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\soloman02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\soloman03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\sun01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\sun02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\sun03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\sun04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\sun05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\sun06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\sun07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\sun08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\sun09.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\victoria01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\victoria02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\victoria03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\victoria04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\victoria05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\victoria06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\victoria07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\victoria08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\vital01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\vital02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\vital03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\vital04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\yamaguchi01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\yamaguchi02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\yamaguchi03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2002\\yamaguchi04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\ADIG01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\ADIG02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\ADIG03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\ADIG04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\ADIG05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\ADIG06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\ADIG07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\ADIG08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\BENABD01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\BENABD02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\BENABD03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\BENABD04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\BENABD05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\BENABD06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\BENABD07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\BENABD08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\BENABD09.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\BENABD10.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\BLINOV01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\BLINOV02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\BLINOV03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\BLINOV04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\BLINOV05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\BLINOV06.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\CHEN01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\CHEN02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\CHEN03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\CHEN04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\CHEN06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\CHEN07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\CHEN08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\CHEN10.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\CHEN11.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\CHOE01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\CHOE02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\CHOE03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\DANILO01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\DANILO02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\DANILO03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\DANILO04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\DANILO05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\DANILO06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\EVSTIO01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\EVSTIO02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\EVSTIO03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\EVSTIO04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\EVSTIO05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\EVSTIO06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\EVSTIO07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\EVSTIO08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FALIKS01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FALIKS02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FALIKS03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FALIKS04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FALIKS05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FALIKS06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FEINER01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FEINER02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FEINER03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FONG01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FONG02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FONG03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FONG04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FONG05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FONG06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FONG07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FONG08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\FONG09.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\GADELI01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\GADELI02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\GADELI03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\GORDEL01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\GORDEL02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\GORDEL03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HAGINO01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HAGINO02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HAGINO03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HONG01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HONG02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HONG03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HONG04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HONG05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HONG06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HONG07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HONG08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HSU01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HSU02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HSU03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HSU04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HUAN_B01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HUAN_B02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HUAN_B03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HUAN_B04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HUAN_J01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HUAN_J02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HUAN_J03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HUAN_J04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HUAN_J05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HUAN_J06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HUAN_J07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\HUAN_J08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\ISHIDA01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\ISHIDA02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\ISHIDA03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\ISHIDA04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\IVLEVA01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\IVLEVA02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\IVLEVA03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\IVLEVA04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\IVLEVA05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\IVLEVA06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\IVLEVA07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\IVLEVA08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\IVLEVA09.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KARYAG01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KARYAG02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KARYAG03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KARYAG04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KARYAG05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KARYAG06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KARYAG07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KARYAG08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KIM_B01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KIM_B02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KIM_B03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KIM_B04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KIM_B05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KIM_B06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KIM_B07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KIM_B08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KIM_B09.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KIM_B10.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KIM_J01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KIM_J02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KIM_J03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KIM_J04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KIM_W01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KIM_W02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KIM_W03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KOLESO04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KOLESO05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KOLESO06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KOLESO07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KOLESO08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KOLESS01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KOLESS02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KOLESS03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KRASNI01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KRASNI02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KRASNI03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KRASNI04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KRASNI05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KRASNI06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KRASNI07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KRASNI08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KRASNI09.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KRASNI10.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KRASNI11.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KRASNI12.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KRASNI13.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KRASNI14.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KRASNI15.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KWON01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KWON02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\KWON03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LEE_H01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LEE_H02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LEE_H03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LEE_J01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LEE_J02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LEE_J03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LEE_K01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LEE_K02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LEE_K03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LEE_K04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LEE_K05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LEE_K06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LEE_K07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LEE_K08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LIAO01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LIAO02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LIAO03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LIAO04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LIAO05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LUO01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LUO02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\LUO03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\MATSUM01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\MATSUM02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\MATSUM03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\MATSUM04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\MCVEY01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\MCVEY02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\MCVEY03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\MCVEY04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\MERJAN01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\MERJAN02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\MERJAN03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\MORET01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\MORET03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\NAKAJI01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\NAKAJI02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\NAKAJI03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\OUSSET01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\OUSSET02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\OUSSET03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\POTAMO01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\POTAMO02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\POTAMO03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\RAN01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\RAN02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\RAN03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\RAN04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\RAN05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\RAN06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\RAN07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\RAN08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SCHU01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SCHU02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SCHU03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SCHU04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SCHU05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SCHU06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SCHU07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SCHU08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SCHU09.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SEBAST01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SEBAST02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SEBAST03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SHYBAY01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SHYBAY02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SHYBAY03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SHYBAY04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SHYBAY05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SHYBAY06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SHYBAY07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SINKEV01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SINKEV02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SINKEV03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SINKEV04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SINKEV05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SINKEV06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SINKEV07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SINKEV08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SINKEV09.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SINKEV10.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SINKEV11.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SINKEV12.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SINKEV13.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SOLOM01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SOLOM02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SOLOM03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SOLOM04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SOLOM05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SUDBIN01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SUDBIN02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SUDBIN03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SUN01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SUN02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\SUN03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\TET01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\TET02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\TET03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\TOIVIO01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\TOIVIO02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\TOIVIO03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\UENO01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\UENO02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\UENO03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\USHIKI01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\USHIKI02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\USHIKI03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\USHIKI04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\USHIKI05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\USHIKI06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\YOO01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\YOO02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\YOO03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\YOO04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\YOO05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\YOO06.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\YOO07.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\YOO08.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\YOO09.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\YOU01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\YOU02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\YOU03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\ZHOU01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\ZHOU02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2004\\ZHOU03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Arciglione01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Arciglione02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Arciglione03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Arciglione04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Arciglione05.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Arciglione06.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Arciglione07.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Arciglione08.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Arciglione09.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Arciglione10.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Arciglione11.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Arciglione12.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Arciglione13.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Arciglione14.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Avdeeva01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Avdeeva02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Avdeeva03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Avdeeva05.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Avdeeva06.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Avdeeva07.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Avdeeva08.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Avila01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Avila02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Avila03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Bach01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Bach02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Bach03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Bach04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Benabdallah01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Benabdallah02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Benabdallah03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Benabdallah04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Benabdallah05.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Benabdallah06.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Benabdallah07.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Benabdallah08.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Benabdallah09.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Bogdanovitch01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Bogdanovitch02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Bogdanovitch03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Cai01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Cai02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Cai03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\ChenC01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\ChenC02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\ChenC03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\ChenC04.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\ChenC05.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\ChenC06.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\ChenC07.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\ChenS01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\ChenS02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\ChenS03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\ChenS04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Day01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Day02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Day03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Day04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\DeTurck06.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\DeTurck07.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\DeTurck08.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\DeTurck09.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\DeTurck10.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\DeTurck11.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\DeTurk01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\DeTurk02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\DeTurk03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\DeTurk04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\DeTurk05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Dulu01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Dulu02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Dulu03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Dulu04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Dulu05.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Dulu06.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Dulu07.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Dulu08.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Faliks01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Faliks02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Faliks03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Feiner01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Feiner02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Feiner03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Feiner04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Feiner05.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Fung01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Fung02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Fung03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Goldberg01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Goldberg02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Goldberg03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Guzman01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Guzman02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Guzman03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Guzman04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Han01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Han02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Han03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Hao01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Hao02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Hao03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Hirata01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Hirata02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Hirata03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Hou01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Hou02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Hou03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Huangci01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Huangci02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Huangci03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Huangci04.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Huangci05.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Huangci06.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Huangci07.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Huangci08.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Hwang01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Hwang02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Hwang03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Izzard01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Izzard02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Izzard03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Izzard04.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Jia01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Jia02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Jia03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Katyukova01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Katyukova02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Katyukova03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Kavalerova01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Kavalerova02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Kavalerova03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Kim01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Kim02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\Kim03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\KorchinskayaKogan01.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\KorchinskayaKogan02.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\KorchinskayaKogan03.mid] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\KorchinskayaKogan04.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\KorchinskayaKogan05.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\KorchinskayaKogan06.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\KorchinskayaKogan07.MID] [C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/2006\\KorchinskayaKogan08.MID]"
     ]
    }
   ],
   "source": [
    "for path in ['2002', '2004', '2006', '2008', '2009', '2011', '2013', '2014', '2015', '2017', '2018']:\n",
    "    preprocess_midi_files_under(f'C:/Users/Draco/Documents/GitHub/MusicTransformer-pytorch/dataset/midi_piano_competition/{path}', 'preprocess_8th_note')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "config = load_config()\n",
    "batch_size = config[\"batch_size\"]\n",
    "block_size = config[\"block_size\"]\n",
    "max_iters = config[\"max_iters\"]\n",
    "eval_interval = config[\"eval_interval\"]\n",
    "save_interval = config[\"save_interval\"]\n",
    "learning_rate = config[\"learning_rate\"]\n",
    "eval_iters = config[\"eval_iters\"]\n",
    "n_embd = config[\"n_embd\"]\n",
    "n_head = config[\"n_head\"]\n",
    "n_layer = config[\"n_layer\"]\n",
    "dropout = config[\"dropout\"]\n",
    "vocab_size = config[\"vocab_size\"]\n",
    "device = config[\"device\"]\n",
    "generated_event_length = config[\"generated_event_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.908165 M parameters\n",
      "step 0: train loss 2.4062, val loss 2.4250\n",
      "step 100: train loss 2.4004, val loss 2.3865\n",
      "step 200: train loss 2.3948, val loss 2.3898\n",
      "step 300: train loss 2.3944, val loss 2.3934\n",
      "step 400: train loss 2.3976, val loss 2.3876\n",
      "step 500: train loss 2.3874, val loss 2.3927\n",
      "step 600: train loss 2.3797, val loss 2.3883\n",
      "step 700: train loss 2.3781, val loss 2.3839\n",
      "step 800: train loss 2.4047, val loss 2.3867\n",
      "step 900: train loss 2.4036, val loss 2.3887\n",
      "step 1000: train loss 2.3777, val loss 2.3800\n",
      "step 1100: train loss 2.3924, val loss 2.3893\n",
      "step 1200: train loss 2.3927, val loss 2.3968\n",
      "step 1300: train loss 2.3934, val loss 2.3780\n",
      "step 1400: train loss 2.3890, val loss 2.3891\n",
      "step 1500: train loss 2.3921, val loss 2.3928\n",
      "step 1600: train loss 2.3912, val loss 2.3888\n",
      "step 1700: train loss 2.3787, val loss 2.3664\n",
      "step 1800: train loss 2.4029, val loss 2.3759\n",
      "step 1900: train loss 2.3841, val loss 2.3827\n",
      "step 2000: train loss 2.3949, val loss 2.3759\n",
      "step 2100: train loss 2.3819, val loss 2.3966\n",
      "step 2200: train loss 2.3838, val loss 2.3840\n",
      "step 2300: train loss 2.3795, val loss 2.3688\n",
      "step 2400: train loss 2.4015, val loss 2.3932\n",
      "step 2500: train loss 2.3968, val loss 2.3830\n",
      "step 2600: train loss 2.3997, val loss 2.3675\n",
      "step 2700: train loss 2.3911, val loss 2.3852\n",
      "step 2800: train loss 2.3865, val loss 2.3792\n",
      "step 2900: train loss 2.3829, val loss 2.3777\n",
      "step 3000: train loss 2.3687, val loss 2.3799\n",
      "step 3100: train loss 2.3713, val loss 2.3728\n",
      "step 3200: train loss 2.3828, val loss 2.3823\n",
      "step 3300: train loss 2.3909, val loss 2.3848\n",
      "step 3400: train loss 2.3781, val loss 2.3693\n",
      "step 3500: train loss 2.3924, val loss 2.3877\n",
      "step 3600: train loss 2.3832, val loss 2.3923\n",
      "step 3700: train loss 2.3769, val loss 2.3824\n",
      "step 3800: train loss 2.3904, val loss 2.3849\n",
      "step 3900: train loss 2.3890, val loss 2.3667\n",
      "step 4000: train loss 2.3847, val loss 2.3795\n",
      "step 4100: train loss 2.3856, val loss 2.3658\n",
      "step 4200: train loss 2.3693, val loss 2.3691\n",
      "step 4300: train loss 2.3811, val loss 2.3941\n",
      "step 4400: train loss 2.3871, val loss 2.3751\n",
      "step 4500: train loss 2.3917, val loss 2.3718\n",
      "step 4600: train loss 2.3901, val loss 2.3875\n",
      "step 4700: train loss 2.3861, val loss 2.3850\n",
      "step 4800: train loss 2.3809, val loss 2.4011\n",
      "step 4900: train loss 2.3689, val loss 2.3857\n",
      "step 5000: train loss 2.3772, val loss 2.3735\n",
      "step 5100: train loss 2.3826, val loss 2.3693\n",
      "step 5200: train loss 2.3758, val loss 2.3734\n",
      "step 5300: train loss 2.3745, val loss 2.3778\n",
      "step 5400: train loss 2.3783, val loss 2.3811\n",
      "step 5500: train loss 2.3885, val loss 2.3758\n",
      "step 5600: train loss 2.3797, val loss 2.3701\n",
      "step 5700: train loss 2.3750, val loss 2.3739\n",
      "step 5800: train loss 2.3785, val loss 2.3752\n",
      "step 5900: train loss 2.3665, val loss 2.3663\n",
      "step 6000: train loss 2.3867, val loss 2.3718\n",
      "step 6100: train loss 2.3916, val loss 2.3713\n",
      "step 6200: train loss 2.3713, val loss 2.3667\n",
      "step 6300: train loss 2.3773, val loss 2.3854\n",
      "step 6400: train loss 2.3823, val loss 2.3802\n",
      "step 6500: train loss 2.3838, val loss 2.3697\n",
      "step 6600: train loss 2.3691, val loss 2.3658\n",
      "step 6700: train loss 2.3653, val loss 2.3675\n",
      "step 6800: train loss 2.3796, val loss 2.3928\n",
      "step 6900: train loss 2.3903, val loss 2.3741\n",
      "step 7000: train loss 2.4049, val loss 2.3844\n",
      "step 7100: train loss 2.3923, val loss 2.4028\n",
      "step 7200: train loss 2.3733, val loss 2.3874\n",
      "step 7300: train loss 2.3673, val loss 2.3692\n",
      "step 7400: train loss 2.3849, val loss 2.3825\n",
      "step 7500: train loss 2.3955, val loss 2.3754\n",
      "step 7600: train loss 2.3804, val loss 2.3705\n",
      "step 7700: train loss 2.3882, val loss 2.3810\n",
      "step 7800: train loss 2.3670, val loss 2.3788\n",
      "step 7900: train loss 2.3680, val loss 2.3679\n",
      "step 8000: train loss 2.3714, val loss 2.3705\n",
      "step 8100: train loss 2.3880, val loss 2.3667\n",
      "step 8200: train loss 2.3857, val loss 2.3764\n",
      "step 8300: train loss 2.3929, val loss 2.3780\n",
      "step 8400: train loss 2.3863, val loss 2.3862\n",
      "step 8500: train loss 2.3757, val loss 2.3771\n",
      "step 8600: train loss 2.3929, val loss 2.3735\n",
      "step 8700: train loss 2.3847, val loss 2.3740\n",
      "step 8800: train loss 2.3866, val loss 2.3705\n",
      "step 8900: train loss 2.3794, val loss 2.3614\n",
      "step 9000: train loss 2.3839, val loss 2.3743\n",
      "step 9100: train loss 2.3808, val loss 2.3681\n",
      "step 9200: train loss 2.3987, val loss 2.3836\n",
      "step 9300: train loss 2.3776, val loss 2.3658\n",
      "step 9400: train loss 2.3845, val loss 2.3765\n",
      "step 9500: train loss 2.3834, val loss 2.3694\n",
      "step 9600: train loss 2.3892, val loss 2.3790\n",
      "step 9700: train loss 2.3756, val loss 2.3782\n",
      "step 9800: train loss 2.3758, val loss 2.3621\n",
      "step 9900: train loss 2.3755, val loss 2.3835\n",
      "step 10000: train loss 2.3827, val loss 2.3542\n",
      "step 10100: train loss 2.3843, val loss 2.3706\n",
      "step 10200: train loss 2.3744, val loss 2.3616\n",
      "step 10300: train loss 2.3842, val loss 2.3875\n",
      "step 10400: train loss 2.3865, val loss 2.3779\n",
      "step 10500: train loss 2.3915, val loss 2.3736\n",
      "step 10600: train loss 2.3838, val loss 2.3565\n",
      "step 10700: train loss 2.3802, val loss 2.3810\n",
      "step 10800: train loss 2.3721, val loss 2.3694\n",
      "step 10900: train loss 2.3724, val loss 2.3651\n",
      "step 11000: train loss 2.3870, val loss 2.3782\n",
      "step 11100: train loss 2.3668, val loss 2.3833\n",
      "step 11200: train loss 2.3868, val loss 2.3622\n",
      "step 11300: train loss 2.3632, val loss 2.3714\n",
      "step 11400: train loss 2.3763, val loss 2.3732\n",
      "step 11500: train loss 2.3671, val loss 2.3816\n",
      "step 11600: train loss 2.3923, val loss 2.3886\n",
      "step 11700: train loss 2.3719, val loss 2.3764\n",
      "step 11800: train loss 2.3919, val loss 2.3767\n",
      "step 11900: train loss 2.3802, val loss 2.3771\n",
      "step 12000: train loss 2.3563, val loss 2.3823\n",
      "step 12100: train loss 2.3800, val loss 2.3735\n",
      "step 12200: train loss 2.3803, val loss 2.3783\n",
      "step 12300: train loss 2.3955, val loss 2.3819\n",
      "step 12400: train loss 2.3748, val loss 2.3626\n",
      "step 12500: train loss 2.3833, val loss 2.3669\n",
      "step 12600: train loss 2.3808, val loss 2.3907\n",
      "step 12700: train loss 2.3842, val loss 2.3789\n",
      "step 12800: train loss 2.3850, val loss 2.3920\n",
      "step 12900: train loss 2.3887, val loss 2.3658\n",
      "step 13000: train loss 2.3825, val loss 2.3512\n",
      "step 13100: train loss 2.3857, val loss 2.3697\n",
      "step 13200: train loss 2.3745, val loss 2.3832\n",
      "step 13300: train loss 2.3848, val loss 2.3657\n",
      "step 13400: train loss 2.3840, val loss 2.3694\n",
      "step 13500: train loss 2.3860, val loss 2.3692\n",
      "step 13600: train loss 2.3796, val loss 2.3696\n",
      "step 13700: train loss 2.3776, val loss 2.3586\n",
      "step 13800: train loss 2.3653, val loss 2.3581\n",
      "step 13900: train loss 2.4032, val loss 2.3817\n",
      "step 14000: train loss 2.3803, val loss 2.3733\n",
      "step 14100: train loss 2.3665, val loss 2.3753\n",
      "step 14200: train loss 2.3767, val loss 2.3538\n",
      "step 14300: train loss 2.3765, val loss 2.3758\n",
      "step 14400: train loss 2.3876, val loss 2.3817\n",
      "step 14500: train loss 2.3855, val loss 2.3751\n",
      "step 14600: train loss 2.3904, val loss 2.3729\n",
      "step 14700: train loss 2.3750, val loss 2.3834\n",
      "step 14800: train loss 2.3767, val loss 2.3587\n",
      "step 14900: train loss 2.3661, val loss 2.3915\n",
      "step 15000: train loss 2.3757, val loss 2.3564\n",
      "step 15100: train loss 2.3649, val loss 2.3675\n",
      "step 15200: train loss 2.3778, val loss 2.3752\n",
      "step 15300: train loss 2.3603, val loss 2.3582\n",
      "step 15400: train loss 2.4011, val loss 2.3745\n",
      "step 15500: train loss 2.3802, val loss 2.3730\n",
      "step 15600: train loss 2.3760, val loss 2.3631\n",
      "step 15700: train loss 2.3710, val loss 2.3645\n",
      "step 15800: train loss 2.3704, val loss 2.3794\n",
      "step 15900: train loss 2.3848, val loss 2.3683\n",
      "step 16000: train loss 2.3619, val loss 2.3792\n",
      "step 16100: train loss 2.3695, val loss 2.3689\n",
      "step 16200: train loss 2.3769, val loss 2.3491\n",
      "step 16300: train loss 2.3624, val loss 2.3530\n",
      "step 16400: train loss 2.3853, val loss 2.3801\n",
      "step 16500: train loss 2.3716, val loss 2.3861\n",
      "step 16600: train loss 2.3876, val loss 2.3657\n",
      "step 16700: train loss 2.3626, val loss 2.3945\n",
      "step 16800: train loss 2.3616, val loss 2.3609\n",
      "step 16900: train loss 2.3680, val loss 2.3750\n",
      "step 17000: train loss 2.3844, val loss 2.3882\n",
      "step 17100: train loss 2.3810, val loss 2.3639\n",
      "step 17200: train loss 2.3597, val loss 2.3837\n",
      "step 17300: train loss 2.3866, val loss 2.3786\n",
      "step 17400: train loss 2.3826, val loss 2.3679\n",
      "step 17500: train loss 2.3790, val loss 2.3766\n",
      "step 17600: train loss 2.3748, val loss 2.3709\n",
      "step 17700: train loss 2.3922, val loss 2.3830\n",
      "step 17800: train loss 2.3641, val loss 2.3771\n",
      "step 17900: train loss 2.3736, val loss 2.3748\n",
      "step 18000: train loss 2.3676, val loss 2.3530\n",
      "step 18100: train loss 2.3682, val loss 2.3708\n",
      "step 18200: train loss 2.3825, val loss 2.3715\n",
      "step 18300: train loss 2.3698, val loss 2.3523\n",
      "step 18400: train loss 2.3820, val loss 2.3618\n",
      "step 18500: train loss 2.3774, val loss 2.3820\n",
      "step 18600: train loss 2.3785, val loss 2.3666\n",
      "step 18700: train loss 2.3697, val loss 2.3786\n",
      "step 18800: train loss 2.3731, val loss 2.3682\n",
      "step 18900: train loss 2.3880, val loss 2.3569\n",
      "step 19000: train loss 2.3648, val loss 2.3742\n",
      "step 19100: train loss 2.3723, val loss 2.3810\n",
      "step 19200: train loss 2.3646, val loss 2.3698\n",
      "step 19300: train loss 2.3733, val loss 2.3597\n",
      "step 19400: train loss 2.3826, val loss 2.3805\n",
      "step 19500: train loss 2.3851, val loss 2.3827\n",
      "step 19600: train loss 2.3621, val loss 2.3691\n",
      "step 19700: train loss 2.3673, val loss 2.3688\n",
      "step 19800: train loss 2.3752, val loss 2.3772\n",
      "step 19900: train loss 2.3873, val loss 2.3642\n",
      "step 20000: train loss 2.3632, val loss 2.3759\n",
      "step 20100: train loss 2.3841, val loss 2.3720\n",
      "step 20200: train loss 2.3635, val loss 2.3689\n",
      "step 20300: train loss 2.3532, val loss 2.3931\n",
      "step 20400: train loss 2.3706, val loss 2.3624\n",
      "step 20500: train loss 2.3625, val loss 2.3763\n",
      "step 20600: train loss 2.3683, val loss 2.3764\n",
      "step 20700: train loss 2.3623, val loss 2.3691\n",
      "step 20800: train loss 2.3706, val loss 2.3702\n",
      "step 20900: train loss 2.3687, val loss 2.3635\n",
      "step 21000: train loss 2.3797, val loss 2.3643\n",
      "step 21100: train loss 2.3730, val loss 2.3752\n",
      "step 21200: train loss 2.3551, val loss 2.3739\n",
      "step 21300: train loss 2.3824, val loss 2.3656\n",
      "step 21400: train loss 2.3625, val loss 2.3707\n",
      "step 21500: train loss 2.3784, val loss 2.3720\n",
      "step 21600: train loss 2.3659, val loss 2.3765\n",
      "step 21700: train loss 2.3770, val loss 2.3650\n",
      "step 21800: train loss 2.3734, val loss 2.3787\n",
      "step 21900: train loss 2.3914, val loss 2.3564\n",
      "step 22000: train loss 2.3656, val loss 2.3726\n",
      "step 22100: train loss 2.3720, val loss 2.3605\n",
      "step 22200: train loss 2.3608, val loss 2.3678\n",
      "step 22300: train loss 2.3745, val loss 2.3640\n",
      "step 22400: train loss 2.3790, val loss 2.3674\n",
      "step 22500: train loss 2.3737, val loss 2.3722\n",
      "step 22600: train loss 2.3799, val loss 2.3758\n",
      "step 22700: train loss 2.3657, val loss 2.3666\n",
      "step 22800: train loss 2.3810, val loss 2.3894\n",
      "step 22900: train loss 2.3694, val loss 2.3698\n",
      "step 23000: train loss 2.3712, val loss 2.3766\n",
      "step 23100: train loss 2.3843, val loss 2.3704\n",
      "step 23200: train loss 2.3673, val loss 2.3795\n",
      "step 23300: train loss 2.3797, val loss 2.3709\n",
      "step 23400: train loss 2.3502, val loss 2.3799\n",
      "step 23500: train loss 2.3641, val loss 2.3600\n",
      "step 23600: train loss 2.3786, val loss 2.3576\n",
      "step 23700: train loss 2.3698, val loss 2.3678\n",
      "step 23800: train loss 2.3570, val loss 2.3605\n",
      "step 23900: train loss 2.3730, val loss 2.3781\n",
      "step 24000: train loss 2.3817, val loss 2.3791\n",
      "step 24100: train loss 2.3718, val loss 2.3692\n",
      "step 24200: train loss 2.3884, val loss 2.3698\n",
      "step 24300: train loss 2.3642, val loss 2.3772\n",
      "step 24400: train loss 2.3633, val loss 2.3730\n",
      "step 24500: train loss 2.3699, val loss 2.3640\n",
      "step 24600: train loss 2.3788, val loss 2.3712\n",
      "step 24700: train loss 2.3721, val loss 2.3676\n",
      "step 24800: train loss 2.3613, val loss 2.3718\n",
      "step 24900: train loss 2.3832, val loss 2.3709\n",
      "step 25000: train loss 2.3695, val loss 2.3732\n",
      "step 25100: train loss 2.3694, val loss 2.3648\n",
      "step 25200: train loss 2.3748, val loss 2.3750\n",
      "step 25300: train loss 2.3721, val loss 2.3711\n",
      "step 25400: train loss 2.3702, val loss 2.3678\n",
      "step 25500: train loss 2.3875, val loss 2.3553\n",
      "step 25600: train loss 2.3786, val loss 2.3705\n",
      "step 25700: train loss 2.3751, val loss 2.3787\n",
      "step 25800: train loss 2.4018, val loss 2.3572\n",
      "step 25900: train loss 2.3752, val loss 2.3791\n",
      "step 26000: train loss 2.3705, val loss 2.3714\n",
      "step 26100: train loss 2.3745, val loss 2.3747\n",
      "step 26200: train loss 2.3631, val loss 2.3573\n",
      "step 26300: train loss 2.3820, val loss 2.3745\n",
      "step 26400: train loss 2.3618, val loss 2.3512\n",
      "step 26500: train loss 2.3681, val loss 2.3739\n",
      "step 26600: train loss 2.3768, val loss 2.3706\n",
      "step 26700: train loss 2.3803, val loss 2.3670\n",
      "step 26800: train loss 2.3680, val loss 2.3737\n",
      "step 26900: train loss 2.3785, val loss 2.3625\n",
      "step 27000: train loss 2.3725, val loss 2.3619\n",
      "step 27100: train loss 2.3815, val loss 2.3589\n",
      "step 27200: train loss 2.3697, val loss 2.3732\n",
      "step 27300: train loss 2.3926, val loss 2.3768\n",
      "step 27400: train loss 2.3617, val loss 2.3690\n",
      "step 27500: train loss 2.3692, val loss 2.3689\n",
      "step 27600: train loss 2.3870, val loss 2.3733\n",
      "step 27700: train loss 2.3634, val loss 2.3788\n",
      "step 27800: train loss 2.3644, val loss 2.3745\n",
      "step 27900: train loss 2.3810, val loss 2.3631\n",
      "step 28000: train loss 2.3690, val loss 2.3664\n",
      "step 28100: train loss 2.3667, val loss 2.3749\n",
      "step 28200: train loss 2.3671, val loss 2.3585\n",
      "step 28300: train loss 2.3748, val loss 2.3545\n",
      "step 28400: train loss 2.3694, val loss 2.3645\n",
      "step 28500: train loss 2.3777, val loss 2.3702\n",
      "step 28600: train loss 2.3746, val loss 2.3769\n",
      "step 28700: train loss 2.3609, val loss 2.3765\n",
      "step 28800: train loss 2.3668, val loss 2.3607\n",
      "step 28900: train loss 2.3754, val loss 2.3592\n",
      "step 29000: train loss 2.3656, val loss 2.3801\n",
      "step 29100: train loss 2.3650, val loss 2.3610\n",
      "step 29200: train loss 2.3673, val loss 2.3577\n",
      "step 29300: train loss 2.3692, val loss 2.3675\n",
      "step 29400: train loss 2.3781, val loss 2.3576\n",
      "step 29500: train loss 2.3732, val loss 2.3675\n",
      "step 29600: train loss 2.3701, val loss 2.3708\n",
      "step 29700: train loss 2.3652, val loss 2.3632\n",
      "step 29800: train loss 2.3822, val loss 2.3537\n",
      "step 29900: train loss 2.3797, val loss 2.3710\n",
      "step 30000: train loss 2.3730, val loss 2.3862\n",
      "step 30100: train loss 2.3863, val loss 2.3731\n",
      "step 30200: train loss 2.3788, val loss 2.3674\n",
      "step 30300: train loss 2.3800, val loss 2.3499\n",
      "step 30400: train loss 2.3973, val loss 2.3620\n",
      "step 30500: train loss 2.3725, val loss 2.3850\n",
      "step 30600: train loss 2.3837, val loss 2.3735\n",
      "step 30700: train loss 2.3629, val loss 2.3639\n",
      "step 30800: train loss 2.3674, val loss 2.3712\n",
      "step 30900: train loss 2.3823, val loss 2.3678\n",
      "step 31000: train loss 2.3810, val loss 2.3599\n",
      "step 31100: train loss 2.3721, val loss 2.3755\n",
      "step 31200: train loss 2.3799, val loss 2.3623\n",
      "step 31300: train loss 2.3606, val loss 2.3664\n",
      "step 31400: train loss 2.3640, val loss 2.3818\n",
      "step 31500: train loss 2.3826, val loss 2.3799\n",
      "step 31600: train loss 2.3794, val loss 2.3750\n",
      "step 31700: train loss 2.3851, val loss 2.3603\n",
      "step 31800: train loss 2.3673, val loss 2.3604\n",
      "step 31900: train loss 2.3791, val loss 2.3718\n",
      "step 32000: train loss 2.3800, val loss 2.3710\n",
      "step 32100: train loss 2.3789, val loss 2.3626\n",
      "step 32200: train loss 2.3855, val loss 2.3673\n",
      "step 32300: train loss 2.3728, val loss 2.3818\n",
      "step 32400: train loss 2.3754, val loss 2.3714\n",
      "step 32500: train loss 2.3721, val loss 2.3768\n",
      "step 32600: train loss 2.3785, val loss 2.3508\n",
      "step 32700: train loss 2.3754, val loss 2.3658\n",
      "step 32800: train loss 2.3675, val loss 2.3768\n",
      "step 32900: train loss 2.3744, val loss 2.3673\n",
      "step 33000: train loss 2.3844, val loss 2.3782\n",
      "step 33100: train loss 2.3759, val loss 2.3607\n",
      "step 33200: train loss 2.3767, val loss 2.3664\n",
      "step 33300: train loss 2.3653, val loss 2.3658\n",
      "step 33400: train loss 2.3667, val loss 2.3552\n",
      "step 33500: train loss 2.3719, val loss 2.3687\n",
      "step 33600: train loss 2.3686, val loss 2.3751\n",
      "step 33700: train loss 2.3694, val loss 2.3567\n",
      "step 33800: train loss 2.3673, val loss 2.3776\n",
      "step 33900: train loss 2.3734, val loss 2.3892\n",
      "step 34000: train loss 2.3557, val loss 2.3614\n",
      "step 34100: train loss 2.3756, val loss 2.3654\n",
      "step 34200: train loss 2.3593, val loss 2.3559\n",
      "step 34300: train loss 2.3900, val loss 2.3716\n",
      "step 34400: train loss 2.3856, val loss 2.3677\n",
      "step 34500: train loss 2.3803, val loss 2.3706\n",
      "step 34600: train loss 2.3618, val loss 2.3686\n",
      "step 34700: train loss 2.3483, val loss 2.3666\n",
      "step 34800: train loss 2.3803, val loss 2.3860\n",
      "step 34900: train loss 2.3648, val loss 2.3597\n",
      "step 35000: train loss 2.3593, val loss 2.3769\n",
      "step 35100: train loss 2.3579, val loss 2.3576\n",
      "step 35200: train loss 2.3520, val loss 2.3608\n",
      "step 35300: train loss 2.3775, val loss 2.3697\n",
      "step 35400: train loss 2.3842, val loss 2.3559\n",
      "step 35500: train loss 2.3757, val loss 2.3602\n",
      "step 35600: train loss 2.3711, val loss 2.3756\n",
      "step 35700: train loss 2.3757, val loss 2.3590\n",
      "step 35800: train loss 2.3692, val loss 2.3780\n",
      "step 35900: train loss 2.3827, val loss 2.3573\n",
      "step 36000: train loss 2.3557, val loss 2.3720\n",
      "step 36100: train loss 2.3581, val loss 2.3641\n",
      "step 36200: train loss 2.3736, val loss 2.3763\n",
      "step 36300: train loss 2.3538, val loss 2.3647\n",
      "step 36400: train loss 2.3650, val loss 2.3468\n",
      "step 36500: train loss 2.3795, val loss 2.3587\n",
      "step 36600: train loss 2.3778, val loss 2.3688\n",
      "step 36700: train loss 2.3591, val loss 2.3679\n",
      "step 36800: train loss 2.3750, val loss 2.3711\n",
      "step 36900: train loss 2.3751, val loss 2.3690\n",
      "step 37000: train loss 2.3720, val loss 2.3658\n",
      "step 37100: train loss 2.3911, val loss 2.3758\n",
      "step 37200: train loss 2.3716, val loss 2.3629\n",
      "step 37300: train loss 2.3686, val loss 2.3884\n",
      "step 37400: train loss 2.3649, val loss 2.3874\n",
      "step 37500: train loss 2.3663, val loss 2.3734\n",
      "step 37600: train loss 2.3715, val loss 2.3578\n",
      "step 37700: train loss 2.3698, val loss 2.3794\n",
      "step 37800: train loss 2.3778, val loss 2.3546\n",
      "step 37900: train loss 2.3731, val loss 2.3626\n",
      "step 38000: train loss 2.3721, val loss 2.3755\n",
      "step 38100: train loss 2.3681, val loss 2.3720\n",
      "step 38200: train loss 2.3730, val loss 2.3685\n",
      "step 38300: train loss 2.3617, val loss 2.3620\n",
      "step 38400: train loss 2.3817, val loss 2.3714\n",
      "step 38500: train loss 2.3854, val loss 2.3612\n",
      "step 38600: train loss 2.3606, val loss 2.3695\n",
      "step 38700: train loss 2.3712, val loss 2.3605\n",
      "step 38800: train loss 2.3802, val loss 2.3711\n",
      "step 38900: train loss 2.3838, val loss 2.3704\n",
      "step 39000: train loss 2.3642, val loss 2.3696\n",
      "step 39100: train loss 2.3593, val loss 2.3548\n",
      "step 39200: train loss 2.3656, val loss 2.3677\n",
      "step 39300: train loss 2.3669, val loss 2.3651\n",
      "step 39400: train loss 2.3696, val loss 2.3586\n",
      "step 39500: train loss 2.3664, val loss 2.3624\n",
      "step 39600: train loss 2.3825, val loss 2.3671\n",
      "step 39700: train loss 2.3843, val loss 2.3656\n",
      "step 39800: train loss 2.3694, val loss 2.3647\n",
      "step 39900: train loss 2.3623, val loss 2.3640\n",
      "step 40000: train loss 2.3859, val loss 2.3631\n",
      "step 40100: train loss 2.3762, val loss 2.3544\n",
      "step 40200: train loss 2.3695, val loss 2.3704\n",
      "step 40300: train loss 2.3728, val loss 2.3643\n",
      "step 40400: train loss 2.3576, val loss 2.3750\n",
      "step 40500: train loss 2.3712, val loss 2.3599\n",
      "step 40600: train loss 2.3688, val loss 2.3658\n",
      "step 40700: train loss 2.3657, val loss 2.3674\n",
      "step 40800: train loss 2.3683, val loss 2.3828\n",
      "step 40900: train loss 2.3689, val loss 2.3802\n",
      "step 41000: train loss 2.3719, val loss 2.3692\n",
      "step 41100: train loss 2.3683, val loss 2.3625\n",
      "step 41200: train loss 2.3723, val loss 2.3673\n",
      "step 41300: train loss 2.3683, val loss 2.3668\n",
      "step 41400: train loss 2.3682, val loss 2.3623\n",
      "step 41500: train loss 2.3728, val loss 2.3842\n",
      "step 41600: train loss 2.3896, val loss 2.3575\n",
      "step 41700: train loss 2.3690, val loss 2.3601\n",
      "step 41800: train loss 2.3726, val loss 2.3646\n",
      "step 41900: train loss 2.3701, val loss 2.3664\n",
      "step 42000: train loss 2.3702, val loss 2.3688\n",
      "step 42100: train loss 2.3785, val loss 2.3723\n",
      "step 42200: train loss 2.3531, val loss 2.3690\n",
      "step 42300: train loss 2.3591, val loss 2.3640\n",
      "step 42400: train loss 2.3570, val loss 2.3645\n",
      "step 42500: train loss 2.3729, val loss 2.3575\n",
      "step 42600: train loss 2.3687, val loss 2.3732\n",
      "step 42700: train loss 2.3780, val loss 2.3671\n",
      "step 42800: train loss 2.3816, val loss 2.3625\n",
      "step 42900: train loss 2.3640, val loss 2.3677\n",
      "step 43000: train loss 2.3734, val loss 2.3613\n",
      "step 43100: train loss 2.3641, val loss 2.3531\n",
      "step 43200: train loss 2.3722, val loss 2.3599\n",
      "step 43300: train loss 2.3661, val loss 2.3675\n",
      "step 43400: train loss 2.3749, val loss 2.3588\n",
      "step 43500: train loss 2.3655, val loss 2.3617\n",
      "step 43600: train loss 2.3730, val loss 2.3620\n",
      "step 43700: train loss 2.3725, val loss 2.3695\n",
      "step 43800: train loss 2.3806, val loss 2.3705\n",
      "step 43900: train loss 2.3713, val loss 2.3471\n",
      "step 44000: train loss 2.3607, val loss 2.3733\n",
      "step 44100: train loss 2.3752, val loss 2.3742\n",
      "step 44200: train loss 2.3699, val loss 2.3704\n",
      "step 44300: train loss 2.3642, val loss 2.3489\n",
      "step 44400: train loss 2.3481, val loss 2.3678\n",
      "step 44500: train loss 2.3625, val loss 2.3626\n",
      "step 44600: train loss 2.3674, val loss 2.3626\n",
      "step 44700: train loss 2.3680, val loss 2.3714\n",
      "step 44800: train loss 2.3802, val loss 2.3667\n",
      "step 44900: train loss 2.3648, val loss 2.3780\n",
      "step 45000: train loss 2.3642, val loss 2.3678\n",
      "step 45100: train loss 2.3635, val loss 2.3717\n",
      "step 45200: train loss 2.3583, val loss 2.3657\n",
      "step 45300: train loss 2.3780, val loss 2.3609\n",
      "step 45400: train loss 2.3634, val loss 2.3631\n",
      "step 45500: train loss 2.3613, val loss 2.3618\n",
      "step 45600: train loss 2.3832, val loss 2.3793\n",
      "step 45700: train loss 2.3681, val loss 2.3617\n",
      "step 45800: train loss 2.3749, val loss 2.3725\n",
      "step 45900: train loss 2.3574, val loss 2.3622\n",
      "step 46000: train loss 2.3625, val loss 2.3665\n",
      "step 46100: train loss 2.3645, val loss 2.3868\n",
      "step 46200: train loss 2.3590, val loss 2.3580\n",
      "step 46300: train loss 2.3710, val loss 2.3808\n",
      "step 46400: train loss 2.3754, val loss 2.3605\n",
      "step 46500: train loss 2.3723, val loss 2.3516\n",
      "step 46600: train loss 2.3695, val loss 2.3663\n",
      "step 46700: train loss 2.3502, val loss 2.3887\n",
      "step 46800: train loss 2.3715, val loss 2.3641\n",
      "step 46900: train loss 2.3778, val loss 2.3623\n",
      "step 47000: train loss 2.3706, val loss 2.3715\n",
      "step 47100: train loss 2.3870, val loss 2.3745\n",
      "step 47200: train loss 2.3848, val loss 2.3743\n",
      "step 47300: train loss 2.3559, val loss 2.3627\n",
      "step 47400: train loss 2.3735, val loss 2.3544\n",
      "step 47500: train loss 2.3710, val loss 2.3540\n",
      "step 47600: train loss 2.3702, val loss 2.3771\n",
      "step 47700: train loss 2.3740, val loss 2.3529\n",
      "step 47800: train loss 2.3820, val loss 2.3723\n",
      "step 47900: train loss 2.3777, val loss 2.3853\n",
      "step 48000: train loss 2.3755, val loss 2.3627\n",
      "step 48100: train loss 2.3603, val loss 2.3675\n",
      "step 48200: train loss 2.3476, val loss 2.3671\n",
      "step 48300: train loss 2.3707, val loss 2.3883\n",
      "step 48400: train loss 2.3709, val loss 2.3742\n",
      "step 48500: train loss 2.3554, val loss 2.3643\n",
      "step 48600: train loss 2.3676, val loss 2.3690\n",
      "step 48700: train loss 2.3735, val loss 2.3614\n",
      "step 48800: train loss 2.3645, val loss 2.3721\n",
      "step 48900: train loss 2.3801, val loss 2.3870\n",
      "step 49000: train loss 2.3700, val loss 2.3491\n",
      "step 49100: train loss 2.3764, val loss 2.3554\n",
      "step 49200: train loss 2.3725, val loss 2.3692\n",
      "step 49300: train loss 2.3685, val loss 2.3805\n",
      "step 49400: train loss 2.3751, val loss 2.3454\n",
      "step 49500: train loss 2.3732, val loss 2.3774\n",
      "step 49600: train loss 2.3648, val loss 2.3620\n",
      "step 49700: train loss 2.3685, val loss 2.3390\n",
      "step 49800: train loss 2.3687, val loss 2.3544\n",
      "step 49900: train loss 2.3745, val loss 2.3567\n",
      "step 50000: train loss 2.3734, val loss 2.3518\n",
      "step 50100: train loss 2.3696, val loss 2.3496\n",
      "step 50200: train loss 2.3696, val loss 2.3698\n",
      "step 50300: train loss 2.3509, val loss 2.3508\n",
      "step 50400: train loss 2.3670, val loss 2.3827\n",
      "step 50500: train loss 2.3690, val loss 2.3525\n",
      "step 50600: train loss 2.3709, val loss 2.3686\n",
      "step 50700: train loss 2.3713, val loss 2.3650\n",
      "step 50800: train loss 2.3744, val loss 2.3663\n",
      "step 50900: train loss 2.3659, val loss 2.3618\n",
      "step 51000: train loss 2.3733, val loss 2.3490\n",
      "step 51100: train loss 2.3605, val loss 2.3666\n",
      "step 51200: train loss 2.3595, val loss 2.3413\n",
      "step 51300: train loss 2.3698, val loss 2.3733\n",
      "step 51400: train loss 2.3655, val loss 2.3699\n",
      "step 51500: train loss 2.3718, val loss 2.3588\n",
      "step 51600: train loss 2.3652, val loss 2.3547\n",
      "step 51700: train loss 2.3715, val loss 2.3664\n",
      "step 51800: train loss 2.3537, val loss 2.3599\n",
      "step 51900: train loss 2.3680, val loss 2.3575\n",
      "step 52000: train loss 2.3735, val loss 2.3767\n",
      "step 52100: train loss 2.3826, val loss 2.3557\n",
      "step 52200: train loss 2.3676, val loss 2.3491\n",
      "step 52300: train loss 2.3738, val loss 2.3678\n",
      "step 52400: train loss 2.3662, val loss 2.3753\n",
      "step 52500: train loss 2.3612, val loss 2.3496\n",
      "step 52600: train loss 2.3704, val loss 2.3601\n",
      "step 52700: train loss 2.3594, val loss 2.3567\n",
      "step 52800: train loss 2.3682, val loss 2.3499\n",
      "step 52900: train loss 2.3705, val loss 2.3609\n",
      "step 53000: train loss 2.3767, val loss 2.3640\n",
      "step 53100: train loss 2.3771, val loss 2.3528\n",
      "step 53200: train loss 2.3728, val loss 2.3644\n",
      "step 53300: train loss 2.3584, val loss 2.3567\n",
      "step 53400: train loss 2.3784, val loss 2.3435\n",
      "step 53500: train loss 2.3582, val loss 2.3605\n",
      "step 53600: train loss 2.3713, val loss 2.3615\n",
      "step 53700: train loss 2.3779, val loss 2.3437\n",
      "step 53800: train loss 2.3747, val loss 2.3427\n",
      "step 53900: train loss 2.3875, val loss 2.3684\n",
      "step 54000: train loss 2.3720, val loss 2.3457\n",
      "step 54100: train loss 2.3765, val loss 2.3810\n",
      "step 54200: train loss 2.3675, val loss 2.3631\n",
      "step 54300: train loss 2.3640, val loss 2.3589\n",
      "step 54400: train loss 2.3608, val loss 2.3699\n",
      "step 54500: train loss 2.3645, val loss 2.3683\n",
      "step 54600: train loss 2.3745, val loss 2.3715\n",
      "step 54700: train loss 2.3626, val loss 2.3463\n",
      "step 54800: train loss 2.3715, val loss 2.3621\n",
      "step 54900: train loss 2.3614, val loss 2.3675\n",
      "step 55000: train loss 2.3778, val loss 2.3476\n",
      "step 55100: train loss 2.3630, val loss 2.3854\n",
      "step 55200: train loss 2.3725, val loss 2.3629\n",
      "step 55300: train loss 2.3778, val loss 2.3604\n",
      "step 55400: train loss 2.3610, val loss 2.3594\n",
      "step 55500: train loss 2.3618, val loss 2.3583\n",
      "step 55600: train loss 2.3582, val loss 2.3684\n",
      "step 55700: train loss 2.3575, val loss 2.3561\n",
      "step 55800: train loss 2.3742, val loss 2.3685\n",
      "step 55900: train loss 2.3822, val loss 2.3708\n",
      "step 56000: train loss 2.3663, val loss 2.3600\n",
      "step 56100: train loss 2.3667, val loss 2.3626\n",
      "step 56200: train loss 2.3917, val loss 2.3559\n",
      "step 56300: train loss 2.3671, val loss 2.3672\n",
      "step 56400: train loss 2.3599, val loss 2.3399\n",
      "step 56500: train loss 2.3817, val loss 2.3654\n",
      "step 56600: train loss 2.3746, val loss 2.3643\n",
      "step 56700: train loss 2.3482, val loss 2.3513\n",
      "step 56800: train loss 2.3656, val loss 2.3702\n",
      "step 56900: train loss 2.3716, val loss 2.3679\n",
      "step 57000: train loss 2.3650, val loss 2.3610\n",
      "step 57100: train loss 2.3714, val loss 2.3550\n",
      "step 57200: train loss 2.3600, val loss 2.3604\n",
      "step 57300: train loss 2.3702, val loss 2.3720\n",
      "step 57400: train loss 2.3688, val loss 2.3747\n",
      "step 57500: train loss 2.3528, val loss 2.3574\n",
      "step 57600: train loss 2.3790, val loss 2.3714\n",
      "step 57700: train loss 2.3720, val loss 2.3527\n",
      "step 57800: train loss 2.3709, val loss 2.3726\n",
      "step 57900: train loss 2.3579, val loss 2.3721\n",
      "step 58000: train loss 2.3593, val loss 2.3791\n",
      "step 58100: train loss 2.3558, val loss 2.3622\n",
      "step 58200: train loss 2.3700, val loss 2.3530\n",
      "step 58300: train loss 2.3752, val loss 2.3685\n",
      "step 58400: train loss 2.3847, val loss 2.3687\n",
      "step 58500: train loss 2.3638, val loss 2.3614\n",
      "step 58600: train loss 2.3615, val loss 2.3755\n",
      "step 58700: train loss 2.3838, val loss 2.3605\n",
      "step 58800: train loss 2.3755, val loss 2.3589\n",
      "step 58900: train loss 2.3705, val loss 2.3555\n",
      "step 59000: train loss 2.3652, val loss 2.3611\n",
      "step 59100: train loss 2.3560, val loss 2.3668\n",
      "step 59200: train loss 2.3745, val loss 2.3632\n",
      "step 59300: train loss 2.3693, val loss 2.3493\n",
      "step 59400: train loss 2.3715, val loss 2.3596\n",
      "step 59500: train loss 2.3810, val loss 2.3635\n",
      "step 59600: train loss 2.3741, val loss 2.3781\n",
      "step 59700: train loss 2.3673, val loss 2.3548\n",
      "step 59800: train loss 2.3668, val loss 2.3639\n",
      "step 59900: train loss 2.3577, val loss 2.3790\n",
      "step 60000: train loss 2.3684, val loss 2.3676\n",
      "step 60100: train loss 2.3683, val loss 2.3757\n",
      "step 60200: train loss 2.3764, val loss 2.3759\n",
      "step 60300: train loss 2.3759, val loss 2.3660\n",
      "step 60400: train loss 2.3705, val loss 2.3736\n",
      "step 60500: train loss 2.3523, val loss 2.3552\n",
      "step 60600: train loss 2.3670, val loss 2.3602\n",
      "step 60700: train loss 2.3635, val loss 2.3564\n",
      "step 60800: train loss 2.3677, val loss 2.3610\n",
      "step 60900: train loss 2.3716, val loss 2.3674\n",
      "step 61000: train loss 2.3718, val loss 2.3566\n",
      "step 61100: train loss 2.3749, val loss 2.3568\n",
      "step 61200: train loss 2.3606, val loss 2.3595\n",
      "step 61300: train loss 2.3652, val loss 2.3650\n",
      "step 61400: train loss 2.3762, val loss 2.3623\n",
      "step 61500: train loss 2.3661, val loss 2.3646\n",
      "step 61600: train loss 2.3630, val loss 2.3537\n",
      "step 61700: train loss 2.3682, val loss 2.3554\n",
      "step 61800: train loss 2.3780, val loss 2.3703\n",
      "step 61900: train loss 2.3797, val loss 2.3620\n",
      "step 62000: train loss 2.3606, val loss 2.3601\n",
      "step 62100: train loss 2.3735, val loss 2.3696\n",
      "step 62200: train loss 2.3691, val loss 2.3637\n",
      "step 62300: train loss 2.3726, val loss 2.3686\n",
      "step 62400: train loss 2.3575, val loss 2.3564\n",
      "step 62500: train loss 2.3502, val loss 2.3620\n",
      "step 62600: train loss 2.3595, val loss 2.3520\n",
      "step 62700: train loss 2.3676, val loss 2.3719\n",
      "step 62800: train loss 2.3609, val loss 2.3520\n",
      "step 62900: train loss 2.3766, val loss 2.3729\n",
      "step 63000: train loss 2.3609, val loss 2.3722\n",
      "step 63100: train loss 2.3567, val loss 2.3782\n",
      "step 63200: train loss 2.3536, val loss 2.3547\n",
      "step 63300: train loss 2.3826, val loss 2.3729\n",
      "step 63400: train loss 2.3707, val loss 2.3736\n",
      "step 63500: train loss 2.3567, val loss 2.3717\n",
      "step 63600: train loss 2.3589, val loss 2.3554\n",
      "step 63700: train loss 2.3652, val loss 2.3551\n",
      "step 63800: train loss 2.3744, val loss 2.3620\n",
      "step 63900: train loss 2.3759, val loss 2.3529\n",
      "step 64000: train loss 2.3655, val loss 2.3663\n",
      "step 64100: train loss 2.3643, val loss 2.3493\n",
      "step 64200: train loss 2.3711, val loss 2.3659\n",
      "step 64300: train loss 2.3705, val loss 2.3605\n",
      "step 64400: train loss 2.3733, val loss 2.3700\n",
      "step 64500: train loss 2.3735, val loss 2.3507\n",
      "step 64600: train loss 2.3715, val loss 2.3672\n",
      "step 64700: train loss 2.3653, val loss 2.3533\n",
      "step 64800: train loss 2.3676, val loss 2.3703\n",
      "step 64900: train loss 2.3749, val loss 2.3531\n",
      "step 65000: train loss 2.3792, val loss 2.3649\n",
      "step 65100: train loss 2.3621, val loss 2.3646\n",
      "step 65200: train loss 2.3737, val loss 2.3626\n",
      "step 65300: train loss 2.3711, val loss 2.3684\n",
      "step 65400: train loss 2.3697, val loss 2.3444\n",
      "step 65500: train loss 2.3774, val loss 2.3856\n",
      "step 65600: train loss 2.3736, val loss 2.3772\n",
      "step 65700: train loss 2.3715, val loss 2.3603\n",
      "step 65800: train loss 2.3813, val loss 2.3673\n",
      "step 65900: train loss 2.3570, val loss 2.3648\n",
      "step 66000: train loss 2.3588, val loss 2.3440\n",
      "step 66100: train loss 2.3637, val loss 2.3688\n",
      "step 66200: train loss 2.3669, val loss 2.3615\n",
      "step 66300: train loss 2.3700, val loss 2.3515\n",
      "step 66400: train loss 2.3717, val loss 2.3754\n",
      "step 66500: train loss 2.3667, val loss 2.3564\n",
      "step 66600: train loss 2.3564, val loss 2.3520\n",
      "step 66700: train loss 2.3660, val loss 2.3682\n",
      "step 66800: train loss 2.3525, val loss 2.3617\n",
      "step 66900: train loss 2.3696, val loss 2.3635\n",
      "step 67000: train loss 2.3585, val loss 2.3824\n",
      "step 67100: train loss 2.3712, val loss 2.3368\n",
      "step 67200: train loss 2.3695, val loss 2.3631\n",
      "step 67300: train loss 2.3696, val loss 2.3577\n",
      "step 67400: train loss 2.3699, val loss 2.3697\n",
      "step 67500: train loss 2.3766, val loss 2.3503\n",
      "step 67600: train loss 2.3623, val loss 2.3597\n",
      "step 67700: train loss 2.3638, val loss 2.3703\n",
      "step 67800: train loss 2.3704, val loss 2.3598\n",
      "step 67900: train loss 2.3770, val loss 2.3662\n",
      "step 68000: train loss 2.3761, val loss 2.3592\n",
      "step 68100: train loss 2.3553, val loss 2.3620\n",
      "step 68200: train loss 2.3643, val loss 2.3636\n",
      "step 68300: train loss 2.3513, val loss 2.3546\n",
      "step 68400: train loss 2.3689, val loss 2.3642\n",
      "step 68500: train loss 2.3756, val loss 2.3684\n",
      "step 68600: train loss 2.3741, val loss 2.3631\n",
      "step 68700: train loss 2.3666, val loss 2.3462\n",
      "step 68800: train loss 2.3669, val loss 2.3465\n",
      "step 68900: train loss 2.3649, val loss 2.3525\n",
      "step 69000: train loss 2.3626, val loss 2.3570\n",
      "step 69100: train loss 2.3888, val loss 2.3431\n",
      "step 69200: train loss 2.3600, val loss 2.3570\n",
      "step 69300: train loss 2.3731, val loss 2.3416\n",
      "step 69400: train loss 2.3729, val loss 2.3570\n",
      "step 69500: train loss 2.3741, val loss 2.3548\n",
      "step 69600: train loss 2.3661, val loss 2.3452\n",
      "step 69700: train loss 2.3545, val loss 2.3604\n",
      "step 69800: train loss 2.3688, val loss 2.3527\n",
      "step 69900: train loss 2.3601, val loss 2.3607\n",
      "step 70000: train loss 2.3627, val loss 2.3635\n",
      "step 70100: train loss 2.3585, val loss 2.3586\n",
      "step 70200: train loss 2.3668, val loss 2.3459\n",
      "step 70300: train loss 2.3805, val loss 2.3776\n",
      "step 70400: train loss 2.3581, val loss 2.3680\n",
      "step 70500: train loss 2.3730, val loss 2.3645\n",
      "step 70600: train loss 2.3686, val loss 2.3589\n",
      "step 70700: train loss 2.3782, val loss 2.3681\n",
      "step 70800: train loss 2.3657, val loss 2.3662\n",
      "step 70900: train loss 2.3441, val loss 2.3534\n",
      "step 71000: train loss 2.3668, val loss 2.3554\n",
      "step 71100: train loss 2.3768, val loss 2.3579\n",
      "step 71200: train loss 2.3611, val loss 2.3674\n",
      "step 71300: train loss 2.3561, val loss 2.3597\n",
      "step 71400: train loss 2.3763, val loss 2.3602\n",
      "step 71500: train loss 2.3737, val loss 2.3541\n",
      "step 71600: train loss 2.3660, val loss 2.3560\n",
      "step 71700: train loss 2.3631, val loss 2.3818\n",
      "step 71800: train loss 2.3641, val loss 2.3629\n",
      "step 71900: train loss 2.3624, val loss 2.3652\n",
      "step 72000: train loss 2.3688, val loss 2.3641\n",
      "step 72100: train loss 2.3530, val loss 2.3653\n",
      "step 72200: train loss 2.3609, val loss 2.3868\n",
      "step 72300: train loss 2.3546, val loss 2.3678\n",
      "step 72400: train loss 2.3770, val loss 2.3462\n",
      "step 72500: train loss 2.3651, val loss 2.3735\n",
      "step 72600: train loss 2.3603, val loss 2.3723\n",
      "step 72700: train loss 2.3751, val loss 2.3594\n",
      "step 72800: train loss 2.3733, val loss 2.3551\n",
      "step 72900: train loss 2.3602, val loss 2.3532\n",
      "step 73000: train loss 2.3650, val loss 2.3588\n",
      "step 73100: train loss 2.3753, val loss 2.3519\n",
      "step 73200: train loss 2.3594, val loss 2.3559\n",
      "step 73300: train loss 2.3586, val loss 2.3778\n",
      "step 73400: train loss 2.3693, val loss 2.3613\n",
      "step 73500: train loss 2.3647, val loss 2.3593\n",
      "step 73600: train loss 2.3708, val loss 2.3580\n",
      "step 73700: train loss 2.3748, val loss 2.3668\n",
      "step 73800: train loss 2.3520, val loss 2.3606\n",
      "step 73900: train loss 2.3754, val loss 2.3547\n",
      "step 74000: train loss 2.3744, val loss 2.3547\n",
      "step 74100: train loss 2.3671, val loss 2.3649\n",
      "step 74200: train loss 2.3534, val loss 2.3554\n",
      "step 74300: train loss 2.3705, val loss 2.3570\n",
      "step 74400: train loss 2.3573, val loss 2.3581\n",
      "step 74500: train loss 2.3707, val loss 2.3529\n",
      "step 74600: train loss 2.3680, val loss 2.3548\n",
      "step 74700: train loss 2.3523, val loss 2.3569\n",
      "step 74800: train loss 2.3528, val loss 2.3412\n",
      "step 74900: train loss 2.3539, val loss 2.3556\n",
      "step 75000: train loss 2.3695, val loss 2.3577\n",
      "step 75100: train loss 2.3751, val loss 2.3673\n",
      "step 75200: train loss 2.3584, val loss 2.3643\n",
      "step 75300: train loss 2.3682, val loss 2.3528\n",
      "step 75400: train loss 2.3595, val loss 2.3320\n",
      "step 75500: train loss 2.3701, val loss 2.3748\n",
      "step 75600: train loss 2.3540, val loss 2.3536\n",
      "step 75700: train loss 2.3705, val loss 2.3723\n",
      "step 75800: train loss 2.3676, val loss 2.3525\n",
      "step 75900: train loss 2.3525, val loss 2.3498\n",
      "step 76000: train loss 2.3711, val loss 2.3641\n",
      "step 76100: train loss 2.3712, val loss 2.3628\n",
      "step 76200: train loss 2.3633, val loss 2.3489\n",
      "step 76300: train loss 2.3763, val loss 2.3577\n",
      "step 76400: train loss 2.3578, val loss 2.3541\n",
      "step 76500: train loss 2.3655, val loss 2.3734\n",
      "step 76600: train loss 2.3606, val loss 2.3594\n",
      "step 76700: train loss 2.3708, val loss 2.3614\n",
      "step 76800: train loss 2.3735, val loss 2.3515\n",
      "step 76900: train loss 2.3626, val loss 2.3722\n",
      "step 77000: train loss 2.3652, val loss 2.3720\n",
      "step 77100: train loss 2.3570, val loss 2.3556\n",
      "step 77200: train loss 2.3657, val loss 2.3474\n",
      "step 77300: train loss 2.3663, val loss 2.3522\n",
      "step 77400: train loss 2.3841, val loss 2.3528\n",
      "step 77500: train loss 2.3564, val loss 2.3598\n",
      "step 77600: train loss 2.3680, val loss 2.3743\n",
      "step 77700: train loss 2.3569, val loss 2.3632\n",
      "step 77800: train loss 2.3690, val loss 2.3682\n",
      "step 77900: train loss 2.3709, val loss 2.3693\n",
      "step 78000: train loss 2.3712, val loss 2.3685\n",
      "step 78100: train loss 2.3772, val loss 2.3651\n",
      "step 78200: train loss 2.3666, val loss 2.3720\n",
      "step 78300: train loss 2.3656, val loss 2.3736\n",
      "step 78400: train loss 2.3523, val loss 2.3537\n",
      "step 78500: train loss 2.3507, val loss 2.3627\n",
      "step 78600: train loss 2.3599, val loss 2.3518\n",
      "step 78700: train loss 2.3696, val loss 2.3642\n",
      "step 78800: train loss 2.3753, val loss 2.3755\n",
      "step 78900: train loss 2.3689, val loss 2.3637\n",
      "step 79000: train loss 2.3700, val loss 2.3610\n",
      "step 79100: train loss 2.3629, val loss 2.3597\n",
      "step 79200: train loss 2.3418, val loss 2.3693\n",
      "step 79300: train loss 2.3538, val loss 2.3744\n",
      "step 79400: train loss 2.3598, val loss 2.3625\n",
      "step 79500: train loss 2.3627, val loss 2.3584\n",
      "step 79600: train loss 2.3614, val loss 2.3461\n",
      "step 79700: train loss 2.3601, val loss 2.3603\n",
      "step 79800: train loss 2.3590, val loss 2.3472\n",
      "step 79900: train loss 2.3570, val loss 2.3680\n",
      "step 80000: train loss 2.3620, val loss 2.3733\n",
      "step 80100: train loss 2.3591, val loss 2.3576\n",
      "step 80200: train loss 2.3713, val loss 2.3542\n",
      "step 80300: train loss 2.3536, val loss 2.3477\n",
      "step 80400: train loss 2.3589, val loss 2.3606\n",
      "step 80500: train loss 2.3650, val loss 2.3616\n",
      "step 80600: train loss 2.3514, val loss 2.3565\n",
      "step 80700: train loss 2.3606, val loss 2.3558\n",
      "step 80800: train loss 2.3647, val loss 2.3621\n",
      "step 80900: train loss 2.3545, val loss 2.3676\n",
      "step 81000: train loss 2.3590, val loss 2.3595\n",
      "step 81100: train loss 2.3630, val loss 2.3706\n",
      "step 81200: train loss 2.3637, val loss 2.3612\n",
      "step 81300: train loss 2.3532, val loss 2.3753\n",
      "step 81400: train loss 2.3576, val loss 2.3535\n",
      "step 81500: train loss 2.3804, val loss 2.3651\n",
      "step 81600: train loss 2.3738, val loss 2.3720\n",
      "step 81700: train loss 2.3673, val loss 2.3631\n",
      "step 81800: train loss 2.3736, val loss 2.3654\n",
      "step 81900: train loss 2.3695, val loss 2.3723\n",
      "step 82000: train loss 2.3701, val loss 2.3577\n",
      "step 82100: train loss 2.3697, val loss 2.3748\n",
      "step 82200: train loss 2.3611, val loss 2.3413\n",
      "step 82300: train loss 2.3687, val loss 2.3775\n",
      "step 82400: train loss 2.3621, val loss 2.3576\n",
      "step 82500: train loss 2.3691, val loss 2.3634\n",
      "step 82600: train loss 2.3652, val loss 2.3604\n",
      "step 82700: train loss 2.3719, val loss 2.3677\n",
      "step 82800: train loss 2.3798, val loss 2.3551\n",
      "step 82900: train loss 2.3556, val loss 2.3520\n",
      "step 83000: train loss 2.3543, val loss 2.3528\n",
      "step 83100: train loss 2.3606, val loss 2.3454\n",
      "step 83200: train loss 2.3712, val loss 2.3562\n",
      "step 83300: train loss 2.3727, val loss 2.3604\n",
      "step 83400: train loss 2.3789, val loss 2.3712\n",
      "step 83500: train loss 2.3651, val loss 2.3465\n",
      "step 83600: train loss 2.3631, val loss 2.3605\n",
      "step 83700: train loss 2.3646, val loss 2.3686\n",
      "step 83800: train loss 2.3548, val loss 2.3576\n",
      "step 83900: train loss 2.3679, val loss 2.3528\n",
      "step 84000: train loss 2.3617, val loss 2.3646\n",
      "step 84100: train loss 2.3655, val loss 2.3397\n",
      "step 84200: train loss 2.3493, val loss 2.3644\n",
      "step 84300: train loss 2.3681, val loss 2.3770\n",
      "step 84400: train loss 2.3726, val loss 2.3476\n",
      "step 84500: train loss 2.3652, val loss 2.3678\n",
      "step 84600: train loss 2.3750, val loss 2.3447\n",
      "step 84700: train loss 2.3546, val loss 2.3760\n",
      "step 84800: train loss 2.3730, val loss 2.3718\n",
      "step 84900: train loss 2.3600, val loss 2.3680\n",
      "step 85000: train loss 2.3658, val loss 2.3760\n",
      "step 85100: train loss 2.3748, val loss 2.3692\n",
      "step 85200: train loss 2.3704, val loss 2.3484\n",
      "step 85300: train loss 2.3737, val loss 2.3697\n",
      "step 85400: train loss 2.3683, val loss 2.3476\n",
      "step 85500: train loss 2.3686, val loss 2.3504\n",
      "step 85600: train loss 2.3629, val loss 2.3734\n",
      "step 85700: train loss 2.3477, val loss 2.3470\n",
      "step 85800: train loss 2.3578, val loss 2.3539\n",
      "step 85900: train loss 2.3651, val loss 2.3631\n",
      "step 86000: train loss 2.3576, val loss 2.3680\n",
      "step 86100: train loss 2.3681, val loss 2.3427\n",
      "step 86200: train loss 2.3540, val loss 2.3349\n",
      "step 86300: train loss 2.3585, val loss 2.3759\n",
      "step 86400: train loss 2.3605, val loss 2.3676\n",
      "step 86500: train loss 2.3511, val loss 2.3587\n",
      "step 86600: train loss 2.3726, val loss 2.3428\n",
      "step 86700: train loss 2.3594, val loss 2.3609\n",
      "step 86800: train loss 2.3478, val loss 2.3653\n",
      "step 86900: train loss 2.3636, val loss 2.3580\n",
      "step 87000: train loss 2.3724, val loss 2.3486\n",
      "step 87100: train loss 2.3551, val loss 2.3663\n",
      "step 87200: train loss 2.3600, val loss 2.3535\n",
      "step 87300: train loss 2.3766, val loss 2.3518\n",
      "step 87400: train loss 2.3810, val loss 2.3560\n",
      "step 87500: train loss 2.3706, val loss 2.3684\n",
      "step 87600: train loss 2.3695, val loss 2.3676\n",
      "step 87700: train loss 2.3663, val loss 2.3528\n",
      "step 87800: train loss 2.3607, val loss 2.3554\n",
      "step 87900: train loss 2.3653, val loss 2.3629\n",
      "step 88000: train loss 2.3759, val loss 2.3521\n",
      "step 88100: train loss 2.3749, val loss 2.3644\n",
      "step 88200: train loss 2.3613, val loss 2.3424\n",
      "step 88300: train loss 2.3766, val loss 2.3595\n",
      "step 88400: train loss 2.3639, val loss 2.3568\n",
      "step 88500: train loss 2.3591, val loss 2.3614\n",
      "step 88600: train loss 2.3504, val loss 2.3619\n",
      "step 88700: train loss 2.3558, val loss 2.3693\n",
      "step 88800: train loss 2.3646, val loss 2.3789\n",
      "step 88900: train loss 2.3588, val loss 2.3407\n",
      "step 89000: train loss 2.3704, val loss 2.3474\n",
      "step 89100: train loss 2.3523, val loss 2.3541\n",
      "step 89200: train loss 2.3727, val loss 2.3452\n",
      "step 89300: train loss 2.3545, val loss 2.3464\n",
      "step 89400: train loss 2.3560, val loss 2.3647\n",
      "step 89500: train loss 2.3608, val loss 2.3721\n",
      "step 89600: train loss 2.3495, val loss 2.3452\n",
      "step 89700: train loss 2.3620, val loss 2.3538\n",
      "step 89800: train loss 2.3536, val loss 2.3693\n",
      "step 89900: train loss 2.3590, val loss 2.3481\n",
      "step 90000: train loss 2.3607, val loss 2.3687\n",
      "step 90100: train loss 2.3717, val loss 2.3526\n",
      "step 90200: train loss 2.3720, val loss 2.3639\n",
      "step 90300: train loss 2.3681, val loss 2.3476\n",
      "step 90400: train loss 2.3673, val loss 2.3640\n",
      "step 90500: train loss 2.3622, val loss 2.3691\n",
      "step 90600: train loss 2.3716, val loss 2.3694\n",
      "step 90700: train loss 2.3546, val loss 2.3495\n",
      "step 90800: train loss 2.3504, val loss 2.3661\n",
      "step 90900: train loss 2.3658, val loss 2.3645\n",
      "step 91000: train loss 2.3781, val loss 2.3651\n",
      "step 91100: train loss 2.3594, val loss 2.3663\n",
      "step 91200: train loss 2.3721, val loss 2.3660\n",
      "step 91300: train loss 2.3534, val loss 2.3721\n",
      "step 91400: train loss 2.3666, val loss 2.3448\n",
      "step 91500: train loss 2.3569, val loss 2.3600\n",
      "step 91600: train loss 2.3731, val loss 2.3682\n",
      "step 91700: train loss 2.3568, val loss 2.3523\n",
      "step 91800: train loss 2.3688, val loss 2.3651\n",
      "step 91900: train loss 2.3559, val loss 2.3619\n",
      "step 92000: train loss 2.3725, val loss 2.3543\n",
      "step 92100: train loss 2.3645, val loss 2.3513\n",
      "step 92200: train loss 2.3558, val loss 2.3654\n",
      "step 92300: train loss 2.3711, val loss 2.3571\n",
      "step 92400: train loss 2.3561, val loss 2.3612\n",
      "step 92500: train loss 2.3568, val loss 2.3587\n",
      "step 92600: train loss 2.3598, val loss 2.3553\n",
      "step 92700: train loss 2.3669, val loss 2.3684\n",
      "step 92800: train loss 2.3631, val loss 2.3761\n",
      "step 92900: train loss 2.3624, val loss 2.3506\n",
      "step 93000: train loss 2.3702, val loss 2.3482\n",
      "step 93100: train loss 2.3590, val loss 2.3815\n",
      "step 93200: train loss 2.3741, val loss 2.3799\n",
      "step 93300: train loss 2.3519, val loss 2.3512\n",
      "step 93400: train loss 2.3398, val loss 2.3724\n",
      "step 93500: train loss 2.3531, val loss 2.3462\n",
      "step 93600: train loss 2.3523, val loss 2.3629\n",
      "step 93700: train loss 2.3682, val loss 2.3465\n",
      "step 93800: train loss 2.3603, val loss 2.3490\n",
      "step 93900: train loss 2.3566, val loss 2.3487\n",
      "step 94000: train loss 2.3698, val loss 2.3637\n",
      "step 94100: train loss 2.3663, val loss 2.3756\n",
      "step 94200: train loss 2.3616, val loss 2.3516\n",
      "step 94300: train loss 2.3740, val loss 2.3776\n",
      "step 94400: train loss 2.3553, val loss 2.3682\n",
      "step 94500: train loss 2.3665, val loss 2.3557\n",
      "step 94600: train loss 2.3545, val loss 2.3451\n",
      "step 94700: train loss 2.3655, val loss 2.3517\n",
      "step 94800: train loss 2.3626, val loss 2.3666\n",
      "step 94900: train loss 2.3654, val loss 2.3500\n",
      "step 95000: train loss 2.3771, val loss 2.3602\n",
      "step 95100: train loss 2.3644, val loss 2.3387\n",
      "step 95200: train loss 2.3699, val loss 2.3607\n",
      "step 95300: train loss 2.3505, val loss 2.3416\n",
      "step 95400: train loss 2.3607, val loss 2.3510\n",
      "step 95500: train loss 2.3504, val loss 2.3646\n",
      "step 95600: train loss 2.3506, val loss 2.3737\n",
      "step 95700: train loss 2.3502, val loss 2.3364\n",
      "step 95800: train loss 2.3601, val loss 2.3487\n",
      "step 95900: train loss 2.3688, val loss 2.3713\n",
      "step 96000: train loss 2.3667, val loss 2.3510\n",
      "step 96100: train loss 2.3691, val loss 2.3603\n",
      "step 96200: train loss 2.3685, val loss 2.3584\n",
      "step 96300: train loss 2.3593, val loss 2.3519\n",
      "step 96400: train loss 2.3573, val loss 2.3699\n",
      "step 96500: train loss 2.3609, val loss 2.3558\n",
      "step 96600: train loss 2.3741, val loss 2.3488\n",
      "step 96700: train loss 2.3673, val loss 2.3569\n",
      "step 96800: train loss 2.3612, val loss 2.3587\n",
      "step 96900: train loss 2.3740, val loss 2.3538\n",
      "step 97000: train loss 2.3609, val loss 2.3720\n",
      "step 97100: train loss 2.3736, val loss 2.3735\n",
      "step 97200: train loss 2.3663, val loss 2.3676\n",
      "step 97300: train loss 2.3676, val loss 2.3664\n",
      "step 97400: train loss 2.3678, val loss 2.3624\n",
      "step 97500: train loss 2.3570, val loss 2.3582\n",
      "step 97600: train loss 2.3557, val loss 2.3549\n",
      "step 97700: train loss 2.3659, val loss 2.3533\n",
      "step 97800: train loss 2.3534, val loss 2.3534\n",
      "step 97900: train loss 2.3494, val loss 2.3731\n",
      "step 98000: train loss 2.3636, val loss 2.3549\n",
      "step 98100: train loss 2.3534, val loss 2.3681\n",
      "step 98200: train loss 2.3652, val loss 2.3739\n",
      "step 98300: train loss 2.3619, val loss 2.3520\n",
      "step 98400: train loss 2.3738, val loss 2.3865\n",
      "step 98500: train loss 2.3765, val loss 2.3530\n",
      "step 98600: train loss 2.3693, val loss 2.3596\n",
      "step 98700: train loss 2.3586, val loss 2.3741\n",
      "step 98800: train loss 2.3889, val loss 2.3592\n",
      "step 98900: train loss 2.3566, val loss 2.3404\n",
      "step 99000: train loss 2.3693, val loss 2.3597\n",
      "step 99100: train loss 2.3493, val loss 2.3383\n",
      "step 99200: train loss 2.3564, val loss 2.3491\n",
      "step 99300: train loss 2.3572, val loss 2.3557\n",
      "step 99400: train loss 2.3573, val loss 2.3580\n",
      "step 99500: train loss 2.3683, val loss 2.3445\n",
      "step 99600: train loss 2.3684, val loss 2.3505\n",
      "step 99700: train loss 2.3667, val loss 2.3606\n",
      "step 99800: train loss 2.3546, val loss 2.3518\n",
      "step 99900: train loss 2.3661, val loss 2.3562\n",
      "step 100000: train loss 2.3613, val loss 2.3556\n",
      "step 100100: train loss 2.3600, val loss 2.3492\n",
      "step 100200: train loss 2.3708, val loss 2.3401\n",
      "step 100300: train loss 2.3577, val loss 2.3581\n",
      "step 100400: train loss 2.3650, val loss 2.3616\n",
      "step 100500: train loss 2.3523, val loss 2.3663\n",
      "step 100600: train loss 2.3598, val loss 2.3656\n",
      "step 100700: train loss 2.3713, val loss 2.3645\n",
      "step 100800: train loss 2.3709, val loss 2.3497\n",
      "step 100900: train loss 2.3628, val loss 2.3604\n",
      "step 101000: train loss 2.3744, val loss 2.3500\n",
      "step 101100: train loss 2.3621, val loss 2.3564\n",
      "step 101200: train loss 2.3657, val loss 2.3512\n",
      "step 101300: train loss 2.3714, val loss 2.3629\n",
      "step 101400: train loss 2.3848, val loss 2.3584\n",
      "step 101500: train loss 2.3680, val loss 2.3630\n",
      "step 101600: train loss 2.3550, val loss 2.3652\n",
      "step 101700: train loss 2.3602, val loss 2.3475\n",
      "step 101800: train loss 2.3808, val loss 2.3517\n",
      "step 101900: train loss 2.3689, val loss 2.3599\n",
      "step 102000: train loss 2.3470, val loss 2.3579\n",
      "step 102100: train loss 2.3657, val loss 2.3477\n",
      "step 102200: train loss 2.3505, val loss 2.3452\n",
      "step 102300: train loss 2.3456, val loss 2.3572\n",
      "step 102400: train loss 2.3574, val loss 2.3610\n",
      "step 102500: train loss 2.3684, val loss 2.3722\n",
      "step 102600: train loss 2.3504, val loss 2.3620\n",
      "step 102700: train loss 2.3647, val loss 2.3553\n",
      "step 102800: train loss 2.3602, val loss 2.3460\n",
      "step 102900: train loss 2.3497, val loss 2.3653\n",
      "step 103000: train loss 2.3635, val loss 2.3513\n",
      "step 103100: train loss 2.3622, val loss 2.3632\n",
      "step 103200: train loss 2.3662, val loss 2.3568\n",
      "step 103300: train loss 2.3572, val loss 2.3573\n",
      "step 103400: train loss 2.3634, val loss 2.3480\n",
      "step 103500: train loss 2.3628, val loss 2.3626\n",
      "step 103600: train loss 2.3641, val loss 2.3541\n",
      "step 103700: train loss 2.3567, val loss 2.3448\n",
      "step 103800: train loss 2.3456, val loss 2.3556\n",
      "step 103900: train loss 2.3482, val loss 2.3520\n",
      "step 104000: train loss 2.3701, val loss 2.3564\n",
      "step 104100: train loss 2.3606, val loss 2.3488\n",
      "step 104200: train loss 2.3580, val loss 2.3765\n",
      "step 104300: train loss 2.3586, val loss 2.3678\n",
      "step 104400: train loss 2.3576, val loss 2.3528\n",
      "step 104500: train loss 2.3612, val loss 2.3416\n",
      "step 104600: train loss 2.3555, val loss 2.3545\n",
      "step 104700: train loss 2.3733, val loss 2.3582\n",
      "step 104800: train loss 2.3588, val loss 2.3475\n",
      "step 104900: train loss 2.3635, val loss 2.3573\n",
      "step 105000: train loss 2.3622, val loss 2.3493\n",
      "step 105100: train loss 2.3660, val loss 2.3586\n",
      "step 105200: train loss 2.3631, val loss 2.3554\n",
      "step 105300: train loss 2.3575, val loss 2.3578\n",
      "step 105400: train loss 2.3858, val loss 2.3447\n",
      "step 105500: train loss 2.3612, val loss 2.3687\n",
      "step 105600: train loss 2.3400, val loss 2.3511\n",
      "step 105700: train loss 2.3630, val loss 2.3644\n",
      "step 105800: train loss 2.3724, val loss 2.3665\n",
      "step 105900: train loss 2.3581, val loss 2.3603\n",
      "step 106000: train loss 2.3679, val loss 2.3604\n",
      "step 106100: train loss 2.3650, val loss 2.3729\n",
      "step 106200: train loss 2.3501, val loss 2.3560\n",
      "step 106300: train loss 2.3594, val loss 2.3427\n",
      "step 106400: train loss 2.3621, val loss 2.3410\n",
      "step 106500: train loss 2.3663, val loss 2.3678\n",
      "step 106600: train loss 2.3592, val loss 2.3490\n",
      "step 106700: train loss 2.3642, val loss 2.3500\n",
      "step 106800: train loss 2.3683, val loss 2.3523\n",
      "step 106900: train loss 2.3349, val loss 2.3602\n",
      "step 107000: train loss 2.3634, val loss 2.3432\n",
      "step 107100: train loss 2.3721, val loss 2.3522\n",
      "step 107200: train loss 2.3587, val loss 2.3590\n",
      "step 107300: train loss 2.3568, val loss 2.3579\n",
      "step 107400: train loss 2.3696, val loss 2.3605\n",
      "step 107500: train loss 2.3615, val loss 2.3560\n",
      "step 107600: train loss 2.3523, val loss 2.3681\n",
      "step 107700: train loss 2.3595, val loss 2.3590\n",
      "step 107800: train loss 2.3713, val loss 2.3551\n",
      "step 107900: train loss 2.3514, val loss 2.3584\n",
      "step 108000: train loss 2.3515, val loss 2.3605\n",
      "step 108100: train loss 2.3623, val loss 2.3644\n",
      "step 108200: train loss 2.3446, val loss 2.3638\n",
      "step 108300: train loss 2.3695, val loss 2.3738\n",
      "step 108400: train loss 2.3638, val loss 2.3493\n",
      "step 108500: train loss 2.3617, val loss 2.3620\n",
      "step 108600: train loss 2.3668, val loss 2.3565\n",
      "step 108700: train loss 2.3570, val loss 2.3337\n",
      "step 108800: train loss 2.3607, val loss 2.3509\n",
      "step 108900: train loss 2.3548, val loss 2.3407\n",
      "step 109000: train loss 2.3541, val loss 2.3464\n",
      "step 109100: train loss 2.3430, val loss 2.3746\n",
      "step 109200: train loss 2.3560, val loss 2.3559\n",
      "step 109300: train loss 2.3590, val loss 2.3608\n",
      "step 109400: train loss 2.3590, val loss 2.3549\n",
      "step 109500: train loss 2.3696, val loss 2.3643\n",
      "step 109600: train loss 2.3679, val loss 2.3617\n",
      "step 109700: train loss 2.3652, val loss 2.3609\n",
      "step 109800: train loss 2.3466, val loss 2.3608\n",
      "step 109900: train loss 2.3684, val loss 2.3471\n",
      "step 110000: train loss 2.3538, val loss 2.3530\n",
      "step 110100: train loss 2.3642, val loss 2.3576\n",
      "step 110200: train loss 2.3628, val loss 2.3460\n",
      "step 110300: train loss 2.3574, val loss 2.3529\n",
      "step 110400: train loss 2.3719, val loss 2.3630\n",
      "step 110500: train loss 2.3489, val loss 2.3610\n",
      "step 110600: train loss 2.3673, val loss 2.3539\n",
      "step 110700: train loss 2.3545, val loss 2.3533\n",
      "step 110800: train loss 2.3561, val loss 2.3579\n",
      "step 110900: train loss 2.3640, val loss 2.3535\n",
      "step 111000: train loss 2.3626, val loss 2.3606\n",
      "step 111100: train loss 2.3541, val loss 2.3529\n",
      "step 111200: train loss 2.3718, val loss 2.3508\n",
      "step 111300: train loss 2.3730, val loss 2.3467\n",
      "step 111400: train loss 2.3537, val loss 2.3550\n",
      "step 111500: train loss 2.3484, val loss 2.3534\n",
      "step 111600: train loss 2.3717, val loss 2.3611\n",
      "step 111700: train loss 2.3540, val loss 2.3607\n",
      "step 111800: train loss 2.3622, val loss 2.3563\n",
      "step 111900: train loss 2.3687, val loss 2.3522\n",
      "step 112000: train loss 2.3649, val loss 2.3565\n",
      "step 112100: train loss 2.3620, val loss 2.3625\n",
      "step 112200: train loss 2.3622, val loss 2.3431\n",
      "step 112300: train loss 2.3579, val loss 2.3659\n",
      "step 112400: train loss 2.3618, val loss 2.3757\n",
      "step 112500: train loss 2.3556, val loss 2.3644\n",
      "step 112600: train loss 2.3681, val loss 2.3379\n",
      "step 112700: train loss 2.3750, val loss 2.3522\n",
      "step 112800: train loss 2.3607, val loss 2.3478\n",
      "step 112900: train loss 2.3525, val loss 2.3502\n",
      "step 113000: train loss 2.3681, val loss 2.3577\n",
      "step 113100: train loss 2.3554, val loss 2.3506\n",
      "step 113200: train loss 2.3511, val loss 2.3584\n",
      "step 113300: train loss 2.3590, val loss 2.3488\n",
      "step 113400: train loss 2.3585, val loss 2.3617\n",
      "step 113500: train loss 2.3715, val loss 2.3577\n",
      "step 113600: train loss 2.3729, val loss 2.3503\n",
      "step 113700: train loss 2.3706, val loss 2.3417\n",
      "step 113800: train loss 2.3599, val loss 2.3764\n",
      "step 113900: train loss 2.3825, val loss 2.3626\n",
      "step 114000: train loss 2.3470, val loss 2.3653\n",
      "step 114100: train loss 2.3591, val loss 2.3436\n",
      "step 114200: train loss 2.3531, val loss 2.3544\n",
      "step 114300: train loss 2.3637, val loss 2.3569\n",
      "step 114400: train loss 2.3688, val loss 2.3626\n",
      "step 114500: train loss 2.3561, val loss 2.3400\n",
      "step 114600: train loss 2.3555, val loss 2.3475\n",
      "step 114700: train loss 2.3760, val loss 2.3567\n",
      "step 114800: train loss 2.3601, val loss 2.3482\n",
      "step 114900: train loss 2.3545, val loss 2.3591\n",
      "step 115000: train loss 2.3693, val loss 2.3488\n",
      "step 115100: train loss 2.3683, val loss 2.3662\n",
      "step 115200: train loss 2.3651, val loss 2.3690\n",
      "step 115300: train loss 2.3684, val loss 2.3344\n",
      "step 115400: train loss 2.3474, val loss 2.3483\n",
      "step 115500: train loss 2.3617, val loss 2.3446\n",
      "step 115600: train loss 2.3682, val loss 2.3734\n",
      "step 115700: train loss 2.3625, val loss 2.3398\n",
      "step 115800: train loss 2.3648, val loss 2.3303\n",
      "step 115900: train loss 2.3618, val loss 2.3637\n",
      "step 116000: train loss 2.3697, val loss 2.3507\n",
      "step 116100: train loss 2.3559, val loss 2.3581\n",
      "step 116200: train loss 2.3721, val loss 2.3552\n",
      "step 116300: train loss 2.3411, val loss 2.3604\n",
      "step 116400: train loss 2.3482, val loss 2.3661\n",
      "step 116500: train loss 2.3573, val loss 2.3691\n",
      "step 116600: train loss 2.3627, val loss 2.3601\n",
      "step 116700: train loss 2.3609, val loss 2.3548\n",
      "step 116800: train loss 2.3883, val loss 2.3539\n",
      "step 116900: train loss 2.3646, val loss 2.3418\n",
      "step 117000: train loss 2.3563, val loss 2.3587\n",
      "step 117100: train loss 2.3346, val loss 2.3650\n",
      "step 117200: train loss 2.3637, val loss 2.3529\n",
      "step 117300: train loss 2.3624, val loss 2.3600\n",
      "step 117400: train loss 2.3600, val loss 2.3682\n",
      "step 117500: train loss 2.3620, val loss 2.3665\n",
      "step 117600: train loss 2.3724, val loss 2.3566\n",
      "step 117700: train loss 2.3631, val loss 2.3484\n",
      "step 117800: train loss 2.3497, val loss 2.3588\n",
      "step 117900: train loss 2.3594, val loss 2.3598\n",
      "step 118000: train loss 2.3473, val loss 2.3587\n",
      "step 118100: train loss 2.3629, val loss 2.3756\n",
      "step 118200: train loss 2.3697, val loss 2.3629\n",
      "step 118300: train loss 2.3732, val loss 2.3403\n",
      "step 118400: train loss 2.3623, val loss 2.3664\n",
      "step 118500: train loss 2.3709, val loss 2.3590\n",
      "step 118600: train loss 2.3641, val loss 2.3520\n",
      "step 118700: train loss 2.3680, val loss 2.3652\n",
      "step 118800: train loss 2.3569, val loss 2.3452\n",
      "step 118900: train loss 2.3660, val loss 2.3744\n",
      "step 119000: train loss 2.3509, val loss 2.3719\n",
      "step 119100: train loss 2.3639, val loss 2.3626\n",
      "step 119200: train loss 2.3520, val loss 2.3608\n",
      "step 119300: train loss 2.3711, val loss 2.3539\n",
      "step 119400: train loss 2.3581, val loss 2.3704\n",
      "step 119500: train loss 2.3573, val loss 2.3568\n",
      "step 119600: train loss 2.3629, val loss 2.3503\n",
      "step 119700: train loss 2.3638, val loss 2.3502\n",
      "step 119800: train loss 2.3632, val loss 2.3593\n",
      "step 119900: train loss 2.3577, val loss 2.3513\n",
      "step 120000: train loss 2.3613, val loss 2.3552\n",
      "step 120100: train loss 2.3552, val loss 2.3442\n",
      "step 120200: train loss 2.3524, val loss 2.3554\n",
      "step 120300: train loss 2.3583, val loss 2.3641\n",
      "step 120400: train loss 2.3644, val loss 2.3480\n",
      "step 120500: train loss 2.3729, val loss 2.3562\n",
      "step 120600: train loss 2.3639, val loss 2.3557\n",
      "step 120700: train loss 2.3565, val loss 2.3583\n",
      "step 120800: train loss 2.3482, val loss 2.3611\n",
      "step 120900: train loss 2.3636, val loss 2.3478\n",
      "step 121000: train loss 2.3635, val loss 2.3518\n",
      "step 121100: train loss 2.3600, val loss 2.3525\n",
      "step 121200: train loss 2.3613, val loss 2.3452\n",
      "step 121300: train loss 2.3757, val loss 2.3555\n",
      "step 121400: train loss 2.3610, val loss 2.3370\n",
      "step 121500: train loss 2.3593, val loss 2.3608\n",
      "step 121600: train loss 2.3659, val loss 2.3469\n",
      "step 121700: train loss 2.3698, val loss 2.3504\n",
      "step 121800: train loss 2.3511, val loss 2.3505\n",
      "step 121900: train loss 2.3653, val loss 2.3552\n",
      "step 122000: train loss 2.3498, val loss 2.3704\n",
      "step 122100: train loss 2.3720, val loss 2.3591\n",
      "step 122200: train loss 2.3845, val loss 2.3483\n",
      "step 122300: train loss 2.3468, val loss 2.3587\n",
      "step 122400: train loss 2.3621, val loss 2.3478\n",
      "step 122500: train loss 2.3625, val loss 2.3423\n",
      "step 122600: train loss 2.3685, val loss 2.3535\n",
      "step 122700: train loss 2.3850, val loss 2.3641\n",
      "step 122800: train loss 2.3506, val loss 2.3387\n",
      "step 122900: train loss 2.3471, val loss 2.3534\n",
      "step 123000: train loss 2.3560, val loss 2.3728\n",
      "step 123100: train loss 2.3673, val loss 2.3659\n",
      "step 123200: train loss 2.3625, val loss 2.3573\n",
      "step 123300: train loss 2.3499, val loss 2.3551\n",
      "step 123400: train loss 2.3626, val loss 2.3537\n",
      "step 123500: train loss 2.3573, val loss 2.3450\n",
      "step 123600: train loss 2.3597, val loss 2.3487\n",
      "step 123700: train loss 2.3523, val loss 2.3624\n",
      "step 123800: train loss 2.3722, val loss 2.3626\n",
      "step 123900: train loss 2.3636, val loss 2.3435\n",
      "step 124000: train loss 2.3776, val loss 2.3468\n",
      "step 124100: train loss 2.3526, val loss 2.3480\n",
      "step 124200: train loss 2.3677, val loss 2.3450\n",
      "step 124300: train loss 2.3793, val loss 2.3549\n",
      "step 124400: train loss 2.3503, val loss 2.3447\n",
      "step 124500: train loss 2.3344, val loss 2.3663\n",
      "step 124600: train loss 2.3543, val loss 2.3633\n",
      "step 124700: train loss 2.3737, val loss 2.3674\n",
      "step 124800: train loss 2.3562, val loss 2.3627\n",
      "step 124900: train loss 2.3662, val loss 2.3597\n",
      "step 125000: train loss 2.3506, val loss 2.3442\n",
      "step 125100: train loss 2.3514, val loss 2.3450\n",
      "step 125200: train loss 2.3620, val loss 2.3630\n",
      "step 125300: train loss 2.3483, val loss 2.3477\n",
      "step 125400: train loss 2.3681, val loss 2.3598\n",
      "step 125500: train loss 2.3619, val loss 2.3616\n",
      "step 125600: train loss 2.3627, val loss 2.3610\n",
      "step 125700: train loss 2.3561, val loss 2.3445\n",
      "step 125800: train loss 2.3618, val loss 2.3462\n",
      "step 125900: train loss 2.3417, val loss 2.3667\n",
      "step 126000: train loss 2.3654, val loss 2.3515\n",
      "step 126100: train loss 2.3490, val loss 2.3543\n",
      "step 126200: train loss 2.3581, val loss 2.3506\n",
      "step 126300: train loss 2.3414, val loss 2.3568\n",
      "step 126400: train loss 2.3401, val loss 2.3526\n",
      "step 126500: train loss 2.3563, val loss 2.3504\n",
      "step 126600: train loss 2.3427, val loss 2.3454\n",
      "step 126700: train loss 2.3559, val loss 2.3610\n",
      "step 126800: train loss 2.3521, val loss 2.3521\n",
      "step 126900: train loss 2.3550, val loss 2.3398\n",
      "step 127000: train loss 2.3719, val loss 2.3639\n",
      "step 127100: train loss 2.3552, val loss 2.3484\n",
      "step 127200: train loss 2.3624, val loss 2.3561\n",
      "step 127300: train loss 2.3540, val loss 2.3494\n",
      "step 127400: train loss 2.3602, val loss 2.3535\n",
      "step 127500: train loss 2.3467, val loss 2.3687\n",
      "step 127600: train loss 2.3687, val loss 2.3497\n",
      "step 127700: train loss 2.3532, val loss 2.3522\n",
      "step 127800: train loss 2.3569, val loss 2.3627\n",
      "step 127900: train loss 2.3493, val loss 2.3417\n",
      "step 128000: train loss 2.3678, val loss 2.3543\n",
      "step 128100: train loss 2.3643, val loss 2.3590\n",
      "step 128200: train loss 2.3514, val loss 2.3437\n",
      "step 128300: train loss 2.3478, val loss 2.3681\n",
      "step 128400: train loss 2.3600, val loss 2.3445\n",
      "step 128500: train loss 2.3511, val loss 2.3546\n",
      "step 128600: train loss 2.3666, val loss 2.3565\n",
      "step 128700: train loss 2.3535, val loss 2.3621\n",
      "step 128800: train loss 2.3533, val loss 2.3643\n",
      "step 128900: train loss 2.3789, val loss 2.3559\n",
      "step 129000: train loss 2.3540, val loss 2.3586\n",
      "step 129100: train loss 2.3766, val loss 2.3621\n",
      "step 129200: train loss 2.3499, val loss 2.3501\n",
      "step 129300: train loss 2.3533, val loss 2.3467\n",
      "step 129400: train loss 2.3637, val loss 2.3506\n",
      "step 129500: train loss 2.3484, val loss 2.3688\n",
      "step 129600: train loss 2.3739, val loss 2.3572\n",
      "step 129700: train loss 2.3584, val loss 2.3523\n",
      "step 129800: train loss 2.3593, val loss 2.3500\n",
      "step 129900: train loss 2.3623, val loss 2.3645\n",
      "step 130000: train loss 2.3553, val loss 2.3620\n",
      "step 130100: train loss 2.3584, val loss 2.3406\n",
      "step 130200: train loss 2.3455, val loss 2.3509\n",
      "step 130300: train loss 2.3576, val loss 2.3421\n",
      "step 130400: train loss 2.3526, val loss 2.3593\n",
      "step 130500: train loss 2.3597, val loss 2.3436\n",
      "step 130600: train loss 2.3669, val loss 2.3601\n",
      "step 130700: train loss 2.3634, val loss 2.3570\n",
      "step 130800: train loss 2.3688, val loss 2.3555\n",
      "step 130900: train loss 2.3622, val loss 2.3559\n",
      "step 131000: train loss 2.3518, val loss 2.3525\n",
      "step 131100: train loss 2.3612, val loss 2.3463\n",
      "step 131200: train loss 2.3539, val loss 2.3505\n",
      "step 131300: train loss 2.3513, val loss 2.3685\n",
      "step 131400: train loss 2.3763, val loss 2.3657\n",
      "step 131500: train loss 2.3614, val loss 2.3593\n",
      "step 131600: train loss 2.3565, val loss 2.3403\n",
      "step 131700: train loss 2.3682, val loss 2.3414\n",
      "step 131800: train loss 2.3577, val loss 2.3434\n",
      "step 131900: train loss 2.3572, val loss 2.3546\n",
      "step 132000: train loss 2.3677, val loss 2.3521\n",
      "step 132100: train loss 2.3654, val loss 2.3453\n",
      "step 132200: train loss 2.3660, val loss 2.3646\n",
      "step 132300: train loss 2.3676, val loss 2.3417\n",
      "step 132400: train loss 2.3630, val loss 2.3608\n",
      "step 132500: train loss 2.3577, val loss 2.3472\n",
      "step 132600: train loss 2.3458, val loss 2.3443\n",
      "step 132700: train loss 2.3651, val loss 2.3484\n",
      "step 132800: train loss 2.3489, val loss 2.3744\n",
      "step 132900: train loss 2.3616, val loss 2.3554\n",
      "step 133000: train loss 2.3475, val loss 2.3508\n",
      "step 133100: train loss 2.3604, val loss 2.3448\n",
      "step 133200: train loss 2.3647, val loss 2.3519\n",
      "step 133300: train loss 2.3549, val loss 2.3462\n",
      "step 133400: train loss 2.3659, val loss 2.3489\n",
      "step 133500: train loss 2.3664, val loss 2.3639\n",
      "step 133600: train loss 2.3627, val loss 2.3641\n",
      "step 133700: train loss 2.3662, val loss 2.3482\n",
      "step 133800: train loss 2.3595, val loss 2.3575\n",
      "step 133900: train loss 2.3743, val loss 2.3550\n",
      "step 134000: train loss 2.3584, val loss 2.3536\n",
      "step 134100: train loss 2.3568, val loss 2.3438\n",
      "step 134200: train loss 2.3461, val loss 2.3659\n",
      "step 134300: train loss 2.3794, val loss 2.3613\n",
      "step 134400: train loss 2.3447, val loss 2.3739\n",
      "step 134500: train loss 2.3429, val loss 2.3426\n",
      "step 134600: train loss 2.3702, val loss 2.3526\n",
      "step 134700: train loss 2.3572, val loss 2.3533\n",
      "step 134800: train loss 2.3662, val loss 2.3634\n",
      "step 134900: train loss 2.3520, val loss 2.3467\n",
      "step 135000: train loss 2.3678, val loss 2.3503\n",
      "step 135100: train loss 2.3643, val loss 2.3637\n",
      "step 135200: train loss 2.3516, val loss 2.3598\n",
      "step 135300: train loss 2.3647, val loss 2.3435\n",
      "step 135400: train loss 2.3533, val loss 2.3496\n",
      "step 135500: train loss 2.3523, val loss 2.3471\n",
      "step 135600: train loss 2.3579, val loss 2.3597\n",
      "step 135700: train loss 2.3520, val loss 2.3513\n",
      "step 135800: train loss 2.3455, val loss 2.3504\n",
      "step 135900: train loss 2.3628, val loss 2.3653\n",
      "step 136000: train loss 2.3563, val loss 2.3719\n",
      "step 136100: train loss 2.3569, val loss 2.3428\n",
      "step 136200: train loss 2.3665, val loss 2.3431\n",
      "step 136300: train loss 2.3582, val loss 2.3623\n",
      "step 136400: train loss 2.3555, val loss 2.3465\n",
      "step 136500: train loss 2.3573, val loss 2.3498\n",
      "step 136600: train loss 2.3590, val loss 2.3592\n",
      "step 136700: train loss 2.3674, val loss 2.3512\n",
      "step 136800: train loss 2.3665, val loss 2.3493\n",
      "step 136900: train loss 2.3600, val loss 2.3591\n",
      "step 137000: train loss 2.3614, val loss 2.3606\n",
      "step 137100: train loss 2.3543, val loss 2.3550\n",
      "step 137200: train loss 2.3664, val loss 2.3669\n",
      "step 137300: train loss 2.3553, val loss 2.3369\n",
      "step 137400: train loss 2.3484, val loss 2.3492\n",
      "step 137500: train loss 2.3561, val loss 2.3572\n",
      "step 137600: train loss 2.3473, val loss 2.3603\n",
      "step 137700: train loss 2.3708, val loss 2.3544\n",
      "step 137800: train loss 2.3593, val loss 2.3712\n",
      "step 137900: train loss 2.3544, val loss 2.3687\n",
      "step 138000: train loss 2.3639, val loss 2.3400\n",
      "step 138100: train loss 2.3654, val loss 2.3479\n",
      "step 138200: train loss 2.3603, val loss 2.3622\n",
      "step 138300: train loss 2.3601, val loss 2.3548\n",
      "step 138400: train loss 2.3572, val loss 2.3517\n",
      "step 138500: train loss 2.3589, val loss 2.3594\n",
      "step 138600: train loss 2.3615, val loss 2.3708\n",
      "step 138700: train loss 2.3598, val loss 2.3441\n",
      "step 138800: train loss 2.3551, val loss 2.3560\n",
      "step 138900: train loss 2.3562, val loss 2.3617\n",
      "step 139000: train loss 2.3386, val loss 2.3495\n",
      "step 139100: train loss 2.3569, val loss 2.3603\n",
      "step 139200: train loss 2.3661, val loss 2.3410\n",
      "step 139300: train loss 2.3634, val loss 2.3500\n",
      "step 139400: train loss 2.3404, val loss 2.3576\n",
      "step 139500: train loss 2.3782, val loss 2.3557\n",
      "step 139600: train loss 2.3579, val loss 2.3432\n",
      "step 139700: train loss 2.3767, val loss 2.3512\n",
      "step 139800: train loss 2.3600, val loss 2.3532\n",
      "step 139900: train loss 2.3667, val loss 2.3613\n",
      "step 140000: train loss 2.3580, val loss 2.3572\n",
      "step 140100: train loss 2.3592, val loss 2.3611\n",
      "step 140200: train loss 2.3594, val loss 2.3430\n",
      "step 140300: train loss 2.3603, val loss 2.3683\n",
      "step 140400: train loss 2.3542, val loss 2.3595\n",
      "step 140500: train loss 2.3507, val loss 2.3550\n",
      "step 140600: train loss 2.3550, val loss 2.3485\n",
      "step 140700: train loss 2.3539, val loss 2.3510\n",
      "step 140800: train loss 2.3648, val loss 2.3505\n",
      "step 140900: train loss 2.3666, val loss 2.3499\n",
      "step 141000: train loss 2.3611, val loss 2.3540\n",
      "step 141100: train loss 2.3591, val loss 2.3676\n",
      "step 141200: train loss 2.3507, val loss 2.3517\n",
      "step 141300: train loss 2.3407, val loss 2.3504\n",
      "step 141400: train loss 2.3739, val loss 2.3619\n",
      "step 141500: train loss 2.3397, val loss 2.3574\n",
      "step 141600: train loss 2.3545, val loss 2.3467\n",
      "step 141700: train loss 2.3591, val loss 2.3521\n",
      "step 141800: train loss 2.3608, val loss 2.3613\n",
      "step 141900: train loss 2.3552, val loss 2.3442\n",
      "step 142000: train loss 2.3601, val loss 2.3465\n",
      "step 142100: train loss 2.3633, val loss 2.3626\n",
      "step 142200: train loss 2.3473, val loss 2.3493\n",
      "step 142300: train loss 2.3624, val loss 2.3461\n",
      "step 142400: train loss 2.3675, val loss 2.3443\n",
      "step 142500: train loss 2.3685, val loss 2.3521\n",
      "step 142600: train loss 2.3756, val loss 2.3728\n",
      "step 142700: train loss 2.3427, val loss 2.3576\n",
      "step 142800: train loss 2.3670, val loss 2.3603\n",
      "step 142900: train loss 2.3632, val loss 2.3602\n",
      "step 143000: train loss 2.3578, val loss 2.3415\n",
      "step 143100: train loss 2.3499, val loss 2.3650\n",
      "step 143200: train loss 2.3654, val loss 2.3644\n",
      "step 143300: train loss 2.3577, val loss 2.3530\n",
      "step 143400: train loss 2.3603, val loss 2.3619\n",
      "step 143500: train loss 2.3580, val loss 2.3524\n",
      "step 143600: train loss 2.3780, val loss 2.3521\n",
      "step 143700: train loss 2.3759, val loss 2.3599\n",
      "step 143800: train loss 2.3477, val loss 2.3600\n",
      "step 143900: train loss 2.3802, val loss 2.3621\n",
      "step 144000: train loss 2.3747, val loss 2.3487\n",
      "step 144100: train loss 2.3471, val loss 2.3460\n",
      "step 144200: train loss 2.3563, val loss 2.3558\n",
      "step 144300: train loss 2.3739, val loss 2.3482\n",
      "step 144400: train loss 2.3618, val loss 2.3729\n",
      "step 144500: train loss 2.3627, val loss 2.3458\n",
      "step 144600: train loss 2.3815, val loss 2.3565\n",
      "step 144700: train loss 2.3667, val loss 2.3572\n",
      "step 144800: train loss 2.3594, val loss 2.3491\n",
      "step 144900: train loss 2.3452, val loss 2.3390\n",
      "step 145000: train loss 2.3619, val loss 2.3549\n",
      "step 145100: train loss 2.3501, val loss 2.3575\n",
      "step 145200: train loss 2.3369, val loss 2.3453\n",
      "step 145300: train loss 2.3554, val loss 2.3362\n",
      "step 145400: train loss 2.3558, val loss 2.3575\n",
      "step 145500: train loss 2.3548, val loss 2.3611\n",
      "step 145600: train loss 2.3620, val loss 2.3596\n",
      "step 145700: train loss 2.3543, val loss 2.3475\n",
      "step 145800: train loss 2.3532, val loss 2.3504\n",
      "step 145900: train loss 2.3677, val loss 2.3447\n",
      "step 146000: train loss 2.3726, val loss 2.3426\n",
      "step 146100: train loss 2.3484, val loss 2.3495\n",
      "step 146200: train loss 2.3531, val loss 2.3591\n",
      "step 146300: train loss 2.3560, val loss 2.3429\n",
      "step 146400: train loss 2.3592, val loss 2.3456\n",
      "step 146500: train loss 2.3571, val loss 2.3547\n",
      "step 146600: train loss 2.3649, val loss 2.3525\n",
      "step 146700: train loss 2.3675, val loss 2.3417\n",
      "step 146800: train loss 2.3809, val loss 2.3397\n",
      "step 146900: train loss 2.3546, val loss 2.3452\n",
      "step 147000: train loss 2.3547, val loss 2.3573\n",
      "step 147100: train loss 2.3586, val loss 2.3577\n",
      "step 147200: train loss 2.3551, val loss 2.3538\n",
      "step 147300: train loss 2.3713, val loss 2.3525\n",
      "step 147400: train loss 2.3730, val loss 2.3448\n",
      "step 147500: train loss 2.3506, val loss 2.3521\n",
      "step 147600: train loss 2.3701, val loss 2.3627\n",
      "step 147700: train loss 2.3570, val loss 2.3480\n",
      "step 147800: train loss 2.3753, val loss 2.3609\n",
      "step 147900: train loss 2.3481, val loss 2.3585\n",
      "step 148000: train loss 2.3609, val loss 2.3633\n",
      "step 148100: train loss 2.3625, val loss 2.3488\n",
      "step 148200: train loss 2.3439, val loss 2.3375\n",
      "step 148300: train loss 2.3632, val loss 2.3525\n",
      "step 148400: train loss 2.3566, val loss 2.3436\n",
      "step 148500: train loss 2.3695, val loss 2.3467\n",
      "step 148600: train loss 2.3514, val loss 2.3496\n",
      "step 148700: train loss 2.3534, val loss 2.3390\n",
      "step 148800: train loss 2.3545, val loss 2.3603\n",
      "step 148900: train loss 2.3683, val loss 2.3603\n",
      "step 149000: train loss 2.3488, val loss 2.3561\n",
      "step 149100: train loss 2.3743, val loss 2.3507\n",
      "step 149200: train loss 2.3365, val loss 2.3694\n",
      "step 149300: train loss 2.3504, val loss 2.3524\n",
      "step 149400: train loss 2.3632, val loss 2.3431\n",
      "step 149500: train loss 2.3707, val loss 2.3444\n",
      "step 149600: train loss 2.3497, val loss 2.3459\n",
      "step 149700: train loss 2.3601, val loss 2.3459\n",
      "step 149800: train loss 2.3529, val loss 2.3559\n",
      "step 149900: train loss 2.3678, val loss 2.3617\n",
      "step 150000: train loss 2.3498, val loss 2.3781\n",
      "step 150100: train loss 2.3581, val loss 2.3683\n",
      "step 150200: train loss 2.3529, val loss 2.3523\n",
      "step 150300: train loss 2.3575, val loss 2.3356\n",
      "step 150400: train loss 2.3560, val loss 2.3649\n",
      "step 150500: train loss 2.3581, val loss 2.3523\n",
      "step 150600: train loss 2.3576, val loss 2.3599\n",
      "step 150700: train loss 2.3630, val loss 2.3456\n",
      "step 150800: train loss 2.3712, val loss 2.3531\n",
      "step 150900: train loss 2.3677, val loss 2.3586\n",
      "step 151000: train loss 2.3573, val loss 2.3631\n",
      "step 151100: train loss 2.3616, val loss 2.3461\n",
      "step 151200: train loss 2.3529, val loss 2.3500\n",
      "step 151300: train loss 2.3427, val loss 2.3474\n",
      "step 151400: train loss 2.3634, val loss 2.3457\n",
      "step 151500: train loss 2.3433, val loss 2.3429\n",
      "step 151600: train loss 2.3458, val loss 2.3528\n",
      "step 151700: train loss 2.3534, val loss 2.3403\n",
      "step 151800: train loss 2.3611, val loss 2.3551\n",
      "step 151900: train loss 2.3404, val loss 2.3399\n",
      "step 152000: train loss 2.3634, val loss 2.3562\n",
      "step 152100: train loss 2.3527, val loss 2.3483\n",
      "step 152200: train loss 2.3454, val loss 2.3490\n",
      "step 152300: train loss 2.3625, val loss 2.3520\n",
      "step 152400: train loss 2.3555, val loss 2.3596\n",
      "step 152500: train loss 2.3547, val loss 2.3501\n",
      "step 152600: train loss 2.3568, val loss 2.3545\n",
      "step 152700: train loss 2.3533, val loss 2.3525\n",
      "step 152800: train loss 2.3494, val loss 2.3532\n",
      "step 152900: train loss 2.3676, val loss 2.3534\n",
      "step 153000: train loss 2.3424, val loss 2.3605\n",
      "step 153100: train loss 2.3595, val loss 2.3437\n",
      "step 153200: train loss 2.3512, val loss 2.3422\n",
      "step 153300: train loss 2.3582, val loss 2.3479\n",
      "step 153400: train loss 2.3599, val loss 2.3610\n",
      "step 153500: train loss 2.3679, val loss 2.3460\n",
      "step 153600: train loss 2.3493, val loss 2.3715\n",
      "step 153700: train loss 2.3715, val loss 2.3526\n",
      "step 153800: train loss 2.3396, val loss 2.3505\n",
      "step 153900: train loss 2.3678, val loss 2.3554\n",
      "step 154000: train loss 2.3627, val loss 2.3696\n",
      "step 154100: train loss 2.3637, val loss 2.3522\n",
      "step 154200: train loss 2.3701, val loss 2.3620\n",
      "step 154300: train loss 2.3649, val loss 2.3529\n",
      "step 154400: train loss 2.3508, val loss 2.3490\n",
      "step 154500: train loss 2.3651, val loss 2.3473\n",
      "step 154600: train loss 2.3494, val loss 2.3552\n",
      "step 154700: train loss 2.3516, val loss 2.3507\n",
      "step 154800: train loss 2.3565, val loss 2.3763\n",
      "step 154900: train loss 2.3615, val loss 2.3701\n",
      "step 155000: train loss 2.3639, val loss 2.3616\n",
      "step 155100: train loss 2.3572, val loss 2.3595\n",
      "step 155200: train loss 2.3501, val loss 2.3588\n",
      "step 155300: train loss 2.3465, val loss 2.3456\n",
      "step 155400: train loss 2.3718, val loss 2.3509\n",
      "step 155500: train loss 2.3473, val loss 2.3543\n",
      "step 155600: train loss 2.3755, val loss 2.3411\n",
      "step 155700: train loss 2.3546, val loss 2.3503\n",
      "step 155800: train loss 2.3514, val loss 2.3535\n",
      "step 155900: train loss 2.3492, val loss 2.3414\n",
      "step 156000: train loss 2.3502, val loss 2.3457\n",
      "step 156100: train loss 2.3662, val loss 2.3552\n",
      "step 156200: train loss 2.3661, val loss 2.3571\n",
      "step 156300: train loss 2.3500, val loss 2.3367\n",
      "step 156400: train loss 2.3663, val loss 2.3602\n",
      "step 156500: train loss 2.3378, val loss 2.3556\n",
      "step 156600: train loss 2.3532, val loss 2.3589\n",
      "step 156700: train loss 2.3510, val loss 2.3472\n",
      "step 156800: train loss 2.3646, val loss 2.3458\n",
      "step 156900: train loss 2.3425, val loss 2.3498\n",
      "step 157000: train loss 2.3514, val loss 2.3451\n",
      "step 157100: train loss 2.3456, val loss 2.3500\n",
      "step 157200: train loss 2.3469, val loss 2.3610\n",
      "step 157300: train loss 2.3714, val loss 2.3703\n",
      "step 157400: train loss 2.3638, val loss 2.3620\n",
      "step 157500: train loss 2.3604, val loss 2.3398\n",
      "step 157600: train loss 2.3711, val loss 2.3591\n",
      "step 157700: train loss 2.3684, val loss 2.3475\n",
      "step 157800: train loss 2.3548, val loss 2.3514\n",
      "step 157900: train loss 2.3513, val loss 2.3432\n",
      "step 158000: train loss 2.3380, val loss 2.3471\n",
      "step 158100: train loss 2.3507, val loss 2.3472\n",
      "step 158200: train loss 2.3561, val loss 2.3333\n",
      "step 158300: train loss 2.3612, val loss 2.3615\n",
      "step 158400: train loss 2.3581, val loss 2.3462\n",
      "step 158500: train loss 2.3556, val loss 2.3270\n",
      "step 158600: train loss 2.3581, val loss 2.3388\n",
      "step 158700: train loss 2.3549, val loss 2.3418\n",
      "step 158800: train loss 2.3531, val loss 2.3494\n",
      "step 158900: train loss 2.3577, val loss 2.3614\n",
      "step 159000: train loss 2.3621, val loss 2.3468\n",
      "step 159100: train loss 2.3550, val loss 2.3473\n",
      "step 159200: train loss 2.3641, val loss 2.3628\n",
      "step 159300: train loss 2.3582, val loss 2.3550\n",
      "step 159400: train loss 2.3471, val loss 2.3560\n",
      "step 159500: train loss 2.3452, val loss 2.3575\n",
      "step 159600: train loss 2.3691, val loss 2.3432\n",
      "step 159700: train loss 2.3487, val loss 2.3558\n",
      "step 159800: train loss 2.3529, val loss 2.3521\n",
      "step 159900: train loss 2.3554, val loss 2.3471\n",
      "step 160000: train loss 2.3572, val loss 2.3641\n",
      "step 160100: train loss 2.3426, val loss 2.3625\n",
      "step 160200: train loss 2.3574, val loss 2.3508\n",
      "step 160300: train loss 2.3561, val loss 2.3446\n",
      "step 160400: train loss 2.3739, val loss 2.3561\n",
      "step 160500: train loss 2.3486, val loss 2.3507\n",
      "step 160600: train loss 2.3599, val loss 2.3449\n",
      "step 160700: train loss 2.3658, val loss 2.3441\n",
      "step 160800: train loss 2.3684, val loss 2.3667\n",
      "step 160900: train loss 2.3638, val loss 2.3528\n",
      "step 161000: train loss 2.3613, val loss 2.3695\n",
      "step 161100: train loss 2.3607, val loss 2.3632\n",
      "step 161200: train loss 2.3662, val loss 2.3461\n",
      "step 161300: train loss 2.3411, val loss 2.3348\n",
      "step 161400: train loss 2.3507, val loss 2.3455\n",
      "step 161500: train loss 2.3617, val loss 2.3665\n",
      "step 161600: train loss 2.3529, val loss 2.3433\n",
      "step 161700: train loss 2.3463, val loss 2.3505\n",
      "step 161800: train loss 2.3428, val loss 2.3438\n",
      "step 161900: train loss 2.3490, val loss 2.3436\n",
      "step 162000: train loss 2.3585, val loss 2.3489\n",
      "step 162100: train loss 2.3558, val loss 2.3561\n",
      "step 162200: train loss 2.3522, val loss 2.3644\n",
      "step 162300: train loss 2.3372, val loss 2.3567\n",
      "step 162400: train loss 2.3763, val loss 2.3567\n",
      "step 162500: train loss 2.3613, val loss 2.3390\n",
      "step 162600: train loss 2.3527, val loss 2.3614\n",
      "step 162700: train loss 2.3796, val loss 2.3488\n",
      "step 162800: train loss 2.3465, val loss 2.3571\n",
      "step 162900: train loss 2.3483, val loss 2.3525\n",
      "step 163000: train loss 2.3552, val loss 2.3565\n",
      "step 163100: train loss 2.3651, val loss 2.3506\n",
      "step 163200: train loss 2.3575, val loss 2.3351\n",
      "step 163300: train loss 2.3556, val loss 2.3420\n",
      "step 163400: train loss 2.3498, val loss 2.3611\n",
      "step 163500: train loss 2.3471, val loss 2.3528\n",
      "step 163600: train loss 2.3679, val loss 2.3356\n",
      "step 163700: train loss 2.3445, val loss 2.3631\n",
      "step 163800: train loss 2.3375, val loss 2.3459\n",
      "step 163900: train loss 2.3498, val loss 2.3447\n",
      "step 164000: train loss 2.3496, val loss 2.3497\n",
      "step 164100: train loss 2.3466, val loss 2.3823\n",
      "step 164200: train loss 2.3422, val loss 2.3577\n",
      "step 164300: train loss 2.3607, val loss 2.3533\n",
      "step 164400: train loss 2.3483, val loss 2.3530\n",
      "step 164500: train loss 2.3593, val loss 2.3398\n",
      "step 164600: train loss 2.3583, val loss 2.3350\n",
      "step 164700: train loss 2.3486, val loss 2.3335\n",
      "step 164800: train loss 2.3456, val loss 2.3565\n",
      "step 164900: train loss 2.3622, val loss 2.3490\n",
      "step 165000: train loss 2.3551, val loss 2.3494\n",
      "step 165100: train loss 2.3555, val loss 2.3553\n",
      "step 165200: train loss 2.3468, val loss 2.3574\n",
      "step 165300: train loss 2.3455, val loss 2.3434\n",
      "step 165400: train loss 2.3441, val loss 2.3422\n",
      "step 165500: train loss 2.3635, val loss 2.3529\n",
      "step 165600: train loss 2.3581, val loss 2.3317\n",
      "step 165700: train loss 2.3574, val loss 2.3606\n",
      "step 165800: train loss 2.3614, val loss 2.3579\n",
      "step 165900: train loss 2.3501, val loss 2.3414\n",
      "step 166000: train loss 2.3667, val loss 2.3629\n",
      "step 166100: train loss 2.3347, val loss 2.3504\n",
      "step 166200: train loss 2.3581, val loss 2.3313\n",
      "step 166300: train loss 2.3683, val loss 2.3308\n",
      "step 166400: train loss 2.3595, val loss 2.3518\n",
      "step 166500: train loss 2.3536, val loss 2.3552\n",
      "step 166600: train loss 2.3675, val loss 2.3421\n",
      "step 166700: train loss 2.3544, val loss 2.3603\n",
      "step 166800: train loss 2.3602, val loss 2.3554\n",
      "step 166900: train loss 2.3643, val loss 2.3410\n",
      "step 167000: train loss 2.3474, val loss 2.3472\n",
      "step 167100: train loss 2.3644, val loss 2.3448\n",
      "step 167200: train loss 2.3619, val loss 2.3423\n",
      "step 167300: train loss 2.3472, val loss 2.3493\n",
      "step 167400: train loss 2.3463, val loss 2.3370\n",
      "step 167500: train loss 2.3478, val loss 2.3506\n",
      "step 167600: train loss 2.3705, val loss 2.3515\n",
      "step 167700: train loss 2.3532, val loss 2.3467\n",
      "step 167800: train loss 2.3497, val loss 2.3550\n",
      "step 167900: train loss 2.3712, val loss 2.3552\n",
      "step 168000: train loss 2.3492, val loss 2.3508\n",
      "step 168100: train loss 2.3641, val loss 2.3591\n",
      "step 168200: train loss 2.3487, val loss 2.3535\n",
      "step 168300: train loss 2.3626, val loss 2.3611\n",
      "step 168400: train loss 2.3484, val loss 2.3533\n",
      "step 168500: train loss 2.3575, val loss 2.3582\n",
      "step 168600: train loss 2.3552, val loss 2.3620\n",
      "step 168700: train loss 2.3388, val loss 2.3401\n",
      "step 168800: train loss 2.3545, val loss 2.3357\n",
      "step 168900: train loss 2.3611, val loss 2.3574\n",
      "step 169000: train loss 2.3565, val loss 2.3481\n",
      "step 169100: train loss 2.3424, val loss 2.3388\n",
      "step 169200: train loss 2.3526, val loss 2.3478\n",
      "step 169300: train loss 2.3578, val loss 2.3502\n",
      "step 169400: train loss 2.3590, val loss 2.3518\n",
      "step 169500: train loss 2.3637, val loss 2.3391\n",
      "step 169600: train loss 2.3787, val loss 2.3370\n",
      "step 169700: train loss 2.3514, val loss 2.3683\n",
      "step 169800: train loss 2.3534, val loss 2.3642\n",
      "step 169900: train loss 2.3491, val loss 2.3747\n",
      "step 170000: train loss 2.3620, val loss 2.3573\n",
      "step 170100: train loss 2.3548, val loss 2.3574\n",
      "step 170200: train loss 2.3569, val loss 2.3546\n",
      "step 170300: train loss 2.3648, val loss 2.3449\n",
      "step 170400: train loss 2.3616, val loss 2.3381\n",
      "step 170500: train loss 2.3381, val loss 2.3470\n",
      "step 170600: train loss 2.3510, val loss 2.3543\n",
      "step 170700: train loss 2.3582, val loss 2.3647\n",
      "step 170800: train loss 2.3492, val loss 2.3545\n",
      "step 170900: train loss 2.3711, val loss 2.3600\n",
      "step 171000: train loss 2.3582, val loss 2.3501\n",
      "step 171100: train loss 2.3451, val loss 2.3545\n",
      "step 171200: train loss 2.3649, val loss 2.3605\n",
      "step 171300: train loss 2.3729, val loss 2.3545\n",
      "step 171400: train loss 2.3699, val loss 2.3589\n",
      "step 171500: train loss 2.3443, val loss 2.3413\n",
      "step 171600: train loss 2.3441, val loss 2.3410\n",
      "step 171700: train loss 2.3642, val loss 2.3452\n",
      "step 171800: train loss 2.3508, val loss 2.3531\n",
      "step 171900: train loss 2.3496, val loss 2.3460\n",
      "step 172000: train loss 2.3388, val loss 2.3570\n",
      "step 172100: train loss 2.3579, val loss 2.3464\n",
      "step 172200: train loss 2.3635, val loss 2.3509\n",
      "step 172300: train loss 2.3536, val loss 2.3531\n",
      "step 172400: train loss 2.3519, val loss 2.3505\n",
      "step 172500: train loss 2.3520, val loss 2.3435\n",
      "step 172600: train loss 2.3440, val loss 2.3401\n",
      "step 172700: train loss 2.3480, val loss 2.3533\n",
      "step 172800: train loss 2.3655, val loss 2.3616\n",
      "step 172900: train loss 2.3498, val loss 2.3503\n",
      "step 173000: train loss 2.3428, val loss 2.3586\n",
      "step 173100: train loss 2.3312, val loss 2.3569\n",
      "step 173200: train loss 2.3592, val loss 2.3341\n",
      "step 173300: train loss 2.3499, val loss 2.3488\n",
      "step 173400: train loss 2.3396, val loss 2.3562\n",
      "step 173500: train loss 2.3634, val loss 2.3530\n",
      "step 173600: train loss 2.3546, val loss 2.3486\n",
      "step 173700: train loss 2.3487, val loss 2.3525\n",
      "step 173800: train loss 2.3491, val loss 2.3536\n",
      "step 173900: train loss 2.3628, val loss 2.3459\n",
      "step 174000: train loss 2.3475, val loss 2.3517\n",
      "step 174100: train loss 2.3466, val loss 2.3535\n",
      "step 174200: train loss 2.3582, val loss 2.3467\n",
      "step 174300: train loss 2.3566, val loss 2.3492\n",
      "step 174400: train loss 2.3576, val loss 2.3373\n",
      "step 174500: train loss 2.3625, val loss 2.3249\n",
      "step 174600: train loss 2.3613, val loss 2.3550\n",
      "step 174700: train loss 2.3462, val loss 2.3489\n",
      "step 174800: train loss 2.3682, val loss 2.3511\n",
      "step 174900: train loss 2.3534, val loss 2.3485\n",
      "step 175000: train loss 2.3438, val loss 2.3429\n",
      "step 175100: train loss 2.3692, val loss 2.3600\n",
      "step 175200: train loss 2.3455, val loss 2.3540\n",
      "step 175300: train loss 2.3508, val loss 2.3407\n",
      "step 175400: train loss 2.3471, val loss 2.3535\n",
      "step 175500: train loss 2.3571, val loss 2.3513\n",
      "step 175600: train loss 2.3566, val loss 2.3518\n",
      "step 175700: train loss 2.3439, val loss 2.3320\n",
      "step 175800: train loss 2.3602, val loss 2.3584\n",
      "step 175900: train loss 2.3615, val loss 2.3442\n",
      "step 176000: train loss 2.3707, val loss 2.3403\n",
      "step 176100: train loss 2.3643, val loss 2.3555\n",
      "step 176200: train loss 2.3533, val loss 2.3394\n",
      "step 176300: train loss 2.3525, val loss 2.3529\n",
      "step 176400: train loss 2.3538, val loss 2.3274\n",
      "step 176500: train loss 2.3655, val loss 2.3405\n",
      "step 176600: train loss 2.3555, val loss 2.3334\n",
      "step 176700: train loss 2.3407, val loss 2.3508\n",
      "step 176800: train loss 2.3663, val loss 2.3433\n",
      "step 176900: train loss 2.3590, val loss 2.3494\n",
      "step 177000: train loss 2.3755, val loss 2.3490\n",
      "step 177100: train loss 2.3602, val loss 2.3493\n",
      "step 177200: train loss 2.3471, val loss 2.3352\n",
      "step 177300: train loss 2.3576, val loss 2.3350\n",
      "step 177400: train loss 2.3405, val loss 2.3429\n",
      "step 177500: train loss 2.3385, val loss 2.3474\n",
      "step 177600: train loss 2.3540, val loss 2.3444\n",
      "step 177700: train loss 2.3566, val loss 2.3585\n",
      "step 177800: train loss 2.3700, val loss 2.3413\n",
      "step 177900: train loss 2.3539, val loss 2.3531\n",
      "step 178000: train loss 2.3656, val loss 2.3436\n",
      "step 178100: train loss 2.3719, val loss 2.3516\n",
      "step 178200: train loss 2.3518, val loss 2.3512\n",
      "step 178300: train loss 2.3416, val loss 2.3339\n",
      "step 178400: train loss 2.3620, val loss 2.3529\n",
      "step 178500: train loss 2.3557, val loss 2.3475\n",
      "step 178600: train loss 2.3712, val loss 2.3456\n",
      "step 178700: train loss 2.3563, val loss 2.3424\n",
      "step 178800: train loss 2.3404, val loss 2.3476\n",
      "step 178900: train loss 2.3524, val loss 2.3336\n",
      "step 179000: train loss 2.3503, val loss 2.3643\n",
      "step 179100: train loss 2.3400, val loss 2.3526\n",
      "step 179200: train loss 2.3566, val loss 2.3606\n",
      "step 179300: train loss 2.3444, val loss 2.3437\n",
      "step 179400: train loss 2.3385, val loss 2.3411\n",
      "step 179500: train loss 2.3521, val loss 2.3470\n",
      "step 179600: train loss 2.3698, val loss 2.3533\n",
      "step 179700: train loss 2.3475, val loss 2.3614\n",
      "step 179800: train loss 2.3510, val loss 2.3467\n",
      "step 179900: train loss 2.3627, val loss 2.3472\n",
      "step 180000: train loss 2.3489, val loss 2.3583\n",
      "step 180100: train loss 2.3535, val loss 2.3423\n",
      "step 180200: train loss 2.3619, val loss 2.3587\n",
      "step 180300: train loss 2.3593, val loss 2.3569\n",
      "step 180400: train loss 2.3568, val loss 2.3559\n",
      "step 180500: train loss 2.3486, val loss 2.3457\n",
      "step 180600: train loss 2.3543, val loss 2.3543\n",
      "step 180700: train loss 2.3572, val loss 2.3618\n",
      "step 180800: train loss 2.3580, val loss 2.3519\n",
      "step 180900: train loss 2.3583, val loss 2.3520\n",
      "step 181000: train loss 2.3608, val loss 2.3409\n",
      "step 181100: train loss 2.3655, val loss 2.3582\n",
      "step 181200: train loss 2.3578, val loss 2.3407\n",
      "step 181300: train loss 2.3517, val loss 2.3469\n",
      "step 181400: train loss 2.3485, val loss 2.3510\n",
      "step 181500: train loss 2.3398, val loss 2.3347\n",
      "step 181600: train loss 2.3586, val loss 2.3523\n",
      "step 181700: train loss 2.3638, val loss 2.3385\n",
      "step 181800: train loss 2.3440, val loss 2.3527\n",
      "step 181900: train loss 2.3540, val loss 2.3566\n",
      "step 182000: train loss 2.3550, val loss 2.3576\n",
      "step 182100: train loss 2.3536, val loss 2.3562\n",
      "step 182200: train loss 2.3545, val loss 2.3600\n",
      "step 182300: train loss 2.3556, val loss 2.3528\n",
      "step 182400: train loss 2.3592, val loss 2.3406\n",
      "step 182500: train loss 2.3448, val loss 2.3360\n",
      "step 182600: train loss 2.3567, val loss 2.3495\n",
      "step 182700: train loss 2.3529, val loss 2.3630\n",
      "step 182800: train loss 2.3423, val loss 2.3380\n",
      "step 182900: train loss 2.3559, val loss 2.3477\n",
      "step 183000: train loss 2.3509, val loss 2.3589\n",
      "step 183100: train loss 2.3450, val loss 2.3343\n",
      "step 183200: train loss 2.3543, val loss 2.3405\n",
      "step 183300: train loss 2.3692, val loss 2.3582\n",
      "step 183400: train loss 2.3545, val loss 2.3476\n",
      "step 183500: train loss 2.3472, val loss 2.3392\n",
      "step 183600: train loss 2.3524, val loss 2.3547\n",
      "step 183700: train loss 2.3467, val loss 2.3427\n",
      "step 183800: train loss 2.3585, val loss 2.3469\n",
      "step 183900: train loss 2.3625, val loss 2.3486\n",
      "step 184000: train loss 2.3493, val loss 2.3416\n",
      "step 184100: train loss 2.3387, val loss 2.3428\n",
      "step 184200: train loss 2.3432, val loss 2.3484\n",
      "step 184300: train loss 2.3525, val loss 2.3469\n",
      "step 184400: train loss 2.3582, val loss 2.3617\n",
      "step 184500: train loss 2.3532, val loss 2.3633\n",
      "step 184600: train loss 2.3540, val loss 2.3442\n",
      "step 184700: train loss 2.3536, val loss 2.3527\n",
      "step 184800: train loss 2.3484, val loss 2.3587\n",
      "step 184900: train loss 2.3394, val loss 2.3448\n",
      "step 185000: train loss 2.3638, val loss 2.3408\n",
      "step 185100: train loss 2.3548, val loss 2.3464\n",
      "step 185200: train loss 2.3528, val loss 2.3484\n",
      "step 185300: train loss 2.3675, val loss 2.3430\n",
      "step 185400: train loss 2.3469, val loss 2.3492\n",
      "step 185500: train loss 2.3424, val loss 2.3520\n",
      "step 185600: train loss 2.3517, val loss 2.3408\n",
      "step 185700: train loss 2.3486, val loss 2.3476\n",
      "step 185800: train loss 2.3466, val loss 2.3523\n",
      "step 185900: train loss 2.3464, val loss 2.3478\n",
      "step 186000: train loss 2.3436, val loss 2.3697\n",
      "step 186100: train loss 2.3530, val loss 2.3397\n",
      "step 186200: train loss 2.3566, val loss 2.3493\n",
      "step 186300: train loss 2.3554, val loss 2.3335\n",
      "step 186400: train loss 2.3495, val loss 2.3397\n",
      "step 186500: train loss 2.3327, val loss 2.3361\n",
      "step 186600: train loss 2.3469, val loss 2.3303\n",
      "step 186700: train loss 2.3445, val loss 2.3501\n",
      "step 186800: train loss 2.3504, val loss 2.3468\n",
      "step 186900: train loss 2.3543, val loss 2.3596\n",
      "step 187000: train loss 2.3520, val loss 2.3557\n",
      "step 187100: train loss 2.3644, val loss 2.3431\n",
      "step 187200: train loss 2.3526, val loss 2.3454\n",
      "step 187300: train loss 2.3558, val loss 2.3602\n",
      "step 187400: train loss 2.3586, val loss 2.3542\n",
      "step 187500: train loss 2.3499, val loss 2.3642\n",
      "step 187600: train loss 2.3471, val loss 2.3630\n",
      "step 187700: train loss 2.3495, val loss 2.3283\n",
      "step 187800: train loss 2.3581, val loss 2.3567\n",
      "step 187900: train loss 2.3603, val loss 2.3462\n",
      "step 188000: train loss 2.3521, val loss 2.3380\n",
      "step 188100: train loss 2.3695, val loss 2.3650\n",
      "step 188200: train loss 2.3604, val loss 2.3436\n",
      "step 188300: train loss 2.3581, val loss 2.3417\n",
      "step 188400: train loss 2.3442, val loss 2.3577\n",
      "step 188500: train loss 2.3698, val loss 2.3410\n",
      "step 188600: train loss 2.3506, val loss 2.3404\n",
      "step 188700: train loss 2.3479, val loss 2.3516\n",
      "step 188800: train loss 2.3497, val loss 2.3494\n",
      "step 188900: train loss 2.3538, val loss 2.3436\n",
      "step 189000: train loss 2.3695, val loss 2.3468\n",
      "step 189100: train loss 2.3458, val loss 2.3335\n",
      "step 189200: train loss 2.3455, val loss 2.3484\n",
      "step 189300: train loss 2.3529, val loss 2.3457\n",
      "step 189400: train loss 2.3563, val loss 2.3622\n",
      "step 189500: train loss 2.3710, val loss 2.3472\n",
      "step 189600: train loss 2.3498, val loss 2.3392\n",
      "step 189700: train loss 2.3658, val loss 2.3451\n",
      "step 189800: train loss 2.3675, val loss 2.3482\n",
      "step 189900: train loss 2.3596, val loss 2.3493\n",
      "step 190000: train loss 2.3789, val loss 2.3422\n",
      "step 190100: train loss 2.3507, val loss 2.3459\n",
      "step 190200: train loss 2.3543, val loss 2.3395\n",
      "step 190300: train loss 2.3519, val loss 2.3594\n",
      "step 190400: train loss 2.3500, val loss 2.3483\n",
      "step 190500: train loss 2.3606, val loss 2.3466\n",
      "step 190600: train loss 2.3560, val loss 2.3508\n",
      "step 190700: train loss 2.3610, val loss 2.3543\n",
      "step 190800: train loss 2.3507, val loss 2.3440\n",
      "step 190900: train loss 2.3619, val loss 2.3499\n",
      "step 191000: train loss 2.3497, val loss 2.3613\n",
      "step 191100: train loss 2.3372, val loss 2.3703\n",
      "step 191200: train loss 2.3462, val loss 2.3450\n",
      "step 191300: train loss 2.3576, val loss 2.3511\n",
      "step 191400: train loss 2.3640, val loss 2.3573\n",
      "step 191500: train loss 2.3537, val loss 2.3454\n",
      "step 191600: train loss 2.3651, val loss 2.3516\n",
      "step 191700: train loss 2.3659, val loss 2.3410\n",
      "step 191800: train loss 2.3518, val loss 2.3480\n",
      "step 191900: train loss 2.3481, val loss 2.3537\n",
      "step 192000: train loss 2.3395, val loss 2.3455\n",
      "step 192100: train loss 2.3503, val loss 2.3237\n",
      "step 192200: train loss 2.3520, val loss 2.3431\n",
      "step 192300: train loss 2.3411, val loss 2.3684\n",
      "step 192400: train loss 2.3495, val loss 2.3587\n",
      "step 192500: train loss 2.3522, val loss 2.3579\n",
      "step 192600: train loss 2.3493, val loss 2.3493\n",
      "step 192700: train loss 2.3520, val loss 2.3539\n",
      "step 192800: train loss 2.3632, val loss 2.3454\n",
      "step 192900: train loss 2.3473, val loss 2.3498\n",
      "step 193000: train loss 2.3468, val loss 2.3439\n",
      "step 193100: train loss 2.3629, val loss 2.3514\n",
      "step 193200: train loss 2.3378, val loss 2.3458\n",
      "step 193300: train loss 2.3707, val loss 2.3622\n",
      "step 193400: train loss 2.3584, val loss 2.3477\n",
      "step 193500: train loss 2.3670, val loss 2.3613\n",
      "step 193600: train loss 2.3474, val loss 2.3432\n",
      "step 193700: train loss 2.3509, val loss 2.3454\n",
      "step 193800: train loss 2.3641, val loss 2.3435\n",
      "step 193900: train loss 2.3705, val loss 2.3540\n",
      "step 194000: train loss 2.3564, val loss 2.3494\n",
      "step 194100: train loss 2.3388, val loss 2.3357\n",
      "step 194200: train loss 2.3520, val loss 2.3549\n",
      "step 194300: train loss 2.3574, val loss 2.3283\n",
      "step 194400: train loss 2.3404, val loss 2.3551\n",
      "step 194500: train loss 2.3511, val loss 2.3440\n",
      "step 194600: train loss 2.3399, val loss 2.3389\n",
      "step 194700: train loss 2.3462, val loss 2.3524\n",
      "step 194800: train loss 2.3421, val loss 2.3517\n",
      "step 194900: train loss 2.3520, val loss 2.3453\n",
      "step 195000: train loss 2.3449, val loss 2.3396\n",
      "step 195100: train loss 2.3510, val loss 2.3397\n",
      "step 195200: train loss 2.3445, val loss 2.3363\n",
      "step 195300: train loss 2.3385, val loss 2.3460\n",
      "step 195400: train loss 2.3610, val loss 2.3519\n",
      "step 195500: train loss 2.3669, val loss 2.3536\n",
      "step 195600: train loss 2.3609, val loss 2.3647\n",
      "step 195700: train loss 2.3583, val loss 2.3451\n",
      "step 195800: train loss 2.3681, val loss 2.3480\n",
      "step 195900: train loss 2.3602, val loss 2.3398\n",
      "step 196000: train loss 2.3691, val loss 2.3483\n",
      "step 196100: train loss 2.3698, val loss 2.3374\n",
      "step 196200: train loss 2.3548, val loss 2.3402\n",
      "step 196300: train loss 2.3466, val loss 2.3467\n",
      "step 196400: train loss 2.3758, val loss 2.3479\n",
      "step 196500: train loss 2.3473, val loss 2.3508\n",
      "step 196600: train loss 2.3492, val loss 2.3541\n",
      "step 196700: train loss 2.3497, val loss 2.3438\n",
      "step 196800: train loss 2.3512, val loss 2.3628\n",
      "step 196900: train loss 2.3394, val loss 2.3376\n",
      "step 197000: train loss 2.3532, val loss 2.3455\n",
      "step 197100: train loss 2.3503, val loss 2.3369\n",
      "step 197200: train loss 2.3594, val loss 2.3521\n",
      "step 197300: train loss 2.3600, val loss 2.3510\n",
      "step 197400: train loss 2.3733, val loss 2.3602\n",
      "step 197500: train loss 2.3426, val loss 2.3552\n",
      "step 197600: train loss 2.3565, val loss 2.3452\n",
      "step 197700: train loss 2.3418, val loss 2.3578\n",
      "step 197800: train loss 2.3494, val loss 2.3417\n",
      "step 197900: train loss 2.3527, val loss 2.3437\n",
      "step 198000: train loss 2.3494, val loss 2.3454\n",
      "step 198100: train loss 2.3629, val loss 2.3656\n",
      "step 198200: train loss 2.3502, val loss 2.3531\n",
      "step 198300: train loss 2.3496, val loss 2.3477\n",
      "step 198400: train loss 2.3493, val loss 2.3432\n",
      "step 198500: train loss 2.3601, val loss 2.3513\n",
      "step 198600: train loss 2.3452, val loss 2.3440\n",
      "step 198700: train loss 2.3529, val loss 2.3390\n",
      "step 198800: train loss 2.3418, val loss 2.3475\n",
      "step 198900: train loss 2.3720, val loss 2.3506\n",
      "step 199000: train loss 2.3549, val loss 2.3479\n",
      "step 199100: train loss 2.3589, val loss 2.3427\n",
      "step 199200: train loss 2.3447, val loss 2.3574\n",
      "step 199300: train loss 2.3604, val loss 2.3451\n",
      "step 199400: train loss 2.3371, val loss 2.3503\n",
      "step 199500: train loss 2.3412, val loss 2.3556\n",
      "step 199600: train loss 2.3653, val loss 2.3702\n",
      "step 199700: train loss 2.3387, val loss 2.3445\n",
      "step 199800: train loss 2.3573, val loss 2.3624\n",
      "step 199900: train loss 2.3499, val loss 2.3620\n",
      "step 200000: train loss 2.3611, val loss 2.3482\n",
      "step 200100: train loss 2.3458, val loss 2.3463\n",
      "step 200200: train loss 2.3472, val loss 2.3452\n",
      "step 200300: train loss 2.3440, val loss 2.3331\n",
      "step 200400: train loss 2.3622, val loss 2.3426\n",
      "step 200500: train loss 2.3682, val loss 2.3461\n",
      "step 200600: train loss 2.3502, val loss 2.3630\n",
      "step 200700: train loss 2.3487, val loss 2.3571\n",
      "step 200800: train loss 2.3597, val loss 2.3406\n",
      "step 200900: train loss 2.3522, val loss 2.3649\n",
      "step 201000: train loss 2.3448, val loss 2.3578\n",
      "step 201100: train loss 2.3479, val loss 2.3586\n",
      "step 201200: train loss 2.3535, val loss 2.3563\n",
      "step 201300: train loss 2.3642, val loss 2.3376\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 114\u001b[0m\n\u001b[0;32m    111\u001b[0m xb, yb \u001b[38;5;241m=\u001b[39m get_batch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# evaluate the loss\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    116\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Draco\\Documents\\Image-Line\\FL Studio\\Settings\\Piano roll scripts\\model.py:127\u001b[0m, in \u001b[0;36mBigramLanguageModel.forward\u001b[1;34m(self, idx, targets)\u001b[0m\n\u001b[0;32m    125\u001b[0m pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_table(torch\u001b[38;5;241m.\u001b[39marange(T, device\u001b[38;5;241m=\u001b[39mdevice)) \u001b[38;5;66;03m# (T,C)\u001b[39;00m\n\u001b[0;32m    126\u001b[0m x \u001b[38;5;241m=\u001b[39m tok_emb \u001b[38;5;241m+\u001b[39m pos_emb \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[0;32m    128\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_f(x) \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[0;32m    129\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(x) \u001b[38;5;66;03m# (B,T,vocab_size)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Draco\\Documents\\Image-Line\\FL Studio\\Settings\\Piano roll scripts\\model.py:104\u001b[0m, in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 104\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msa\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffwd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2(x))\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Draco\\Documents\\Image-Line\\FL Studio\\Settings\\Piano roll scripts\\model.py:73\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     72\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([h(x) \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 73\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[1;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = Data('preprocess').all_data()\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "m = load_model('models/train_2.3818-val_2.3640.pth')\n",
    "\n",
    "data = torch.tensor(Data('preprocess').all_data())\n",
    "# data = torch.tensor(dataset.batch(1,2000)[2], dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def shift_sequence(sequence, rand_ints, lower_bound, upper_bound):\n",
    "    # Clone the sequence to avoid modifying the original tensor\n",
    "    shifted_sequence = sequence.clone()\n",
    "    \n",
    "    # Process each row independently\n",
    "    for i in range(sequence.size(0)):\n",
    "        # Define mask for elements in the specified range for this row\n",
    "        mask = (sequence[i] >= lower_bound) & \\\n",
    "               (sequence[i] < upper_bound)\n",
    "        \n",
    "        # Apply the row-specific shift, clamping within 0, 127]\n",
    "        shifted_sequence[i, mask] = torch.clamp(sequence[i, mask] + rand_ints[i], min=lower_bound, max=upper_bound - 1)\n",
    "    \n",
    "    return shifted_sequence\n",
    "\n",
    "def multiply_sequence(sequence, rand_ints, lower_bound, upper_bound):\n",
    "    # Clone the sequence to avoid modifying the original tensor\n",
    "    multiplied_sequence = sequence.clone()\n",
    "    \n",
    "    # Process each row independently\n",
    "    for i in range(sequence.size(0)):\n",
    "        # Define mask for elements in the specified range for this row\n",
    "        mask = (sequence[i] >= lower_bound) & \\\n",
    "               (sequence[i] < upper_bound)\n",
    "        \n",
    "        # Apply the row-specific shift, clamping within 0, 127]\n",
    "        multiplied_sequence[i, mask] = torch.clamp((sequence[i, mask] - lower_bound) * rand_ints[i] + lower_bound, min=lower_bound, max=upper_bound - 1)\n",
    "    \n",
    "    return multiplied_sequence\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "\n",
    "    # Added pitch shifting during training\n",
    "    note_r_ints = [random.randint(-12, 12) for _ in range(batch_size)]\n",
    "    \n",
    "    note_lb = processor.START_IDX[\"notes\"]\n",
    "    note_ub = processor.START_IDX[\"notes\"] + processor.RANGE_NOTES\n",
    "    new_x = shift_sequence(x, note_r_ints, note_lb, note_ub)\n",
    "    new_y = shift_sequence(y, note_r_ints, note_lb, note_ub)\n",
    "    \n",
    "    # Added velocity shifting during training\n",
    "    vel_r_ints = [random.randint(-10, 10) for _ in range(batch_size)]\n",
    "    vel_lb = processor.START_IDX[\"velocity\"]\n",
    "    vel_ub = processor.START_IDX[\"velocity\"] + processor.RANGE_VEL    \n",
    "    new_x = shift_sequence(new_x, vel_r_ints, vel_lb, vel_ub)\n",
    "    new_y = shift_sequence(new_y, vel_r_ints, vel_lb, vel_ub)\n",
    "\n",
    "    # Added time multiplication during training (trained on various multiplications but tending towards regular speed)\n",
    "    time_r_ints = [random.randint(1, 3) for _ in range(batch_size)]\n",
    "    vel_lb = processor.START_IDX[\"time_shift\"]\n",
    "    vel_ub = processor.START_IDX[\"time_shift\"] + processor.RANGE_TIME_SHIFT  \n",
    "    new_x = multiply_sequence(new_x, time_r_ints, vel_lb, vel_ub)\n",
    "    new_y = multiply_sequence(new_y, time_r_ints, vel_lb, vel_ub)\n",
    "\n",
    "    # Added length multiplication during training\n",
    "    vel_lb = processor.START_IDX[\"length\"]\n",
    "    vel_ub = processor.START_IDX[\"length\"] + processor.RANGE_LEN  \n",
    "    new_x = multiply_sequence(new_x, time_r_ints, vel_lb, vel_ub)\n",
    "    new_y = multiply_sequence(new_y, time_r_ints, vel_lb, vel_ub)\n",
    "    \n",
    "    new_x, new_y = new_x.to(device), new_y.to(device)\n",
    "    return new_x, new_y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    m.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split) \n",
    "            logits, loss = m(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    m.train()\n",
    "    return out\n",
    "\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    if iter % config['save_interval'] == config['save_interval'] - 1:\n",
    "        torch.save(m.state_dict(), f'models/train_{losses[\"train\"]:.4f}-val_{losses[\"val\"]:.4f}.pth')\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(m.state_dict(), f'models/train_{losses[\"train\"]:.4f}-val_{losses[\"val\"]:.4f}.pth')\n",
    "# m = load_model('2000_epochs.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate from the model\n",
    "context = torch.tensor([[306, 59, 150]], device=device)\n",
    "output_sequence = m.generate(context, max_new_tokens=200)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pretty_midi.pretty_midi.PrettyMIDI at 0x211b503e290>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode_midi(output_sequence, \"thing.mid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
